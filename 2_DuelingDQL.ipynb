{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gymnasium[box2d] in c:\\users\\p2100788\\.conda\\envs\\gpu_env\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\users\\p2100788\\.conda\\envs\\gpu_env\\lib\\site-packages (from gymnasium[box2d]) (0.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\p2100788\\.conda\\envs\\gpu_env\\lib\\site-packages (from gymnasium[box2d]) (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\p2100788\\.conda\\envs\\gpu_env\\lib\\site-packages (from gymnasium[box2d]) (1.23.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\p2100788\\.conda\\envs\\gpu_env\\lib\\site-packages (from gymnasium[box2d]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\p2100788\\.conda\\envs\\gpu_env\\lib\\site-packages (from gymnasium[box2d]) (4.4.0)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in c:\\users\\p2100788\\.conda\\envs\\gpu_env\\lib\\site-packages (from gymnasium[box2d]) (0.2.0)\n",
      "Collecting swig==4.*\n",
      "  Downloading swig-4.1.1-py2.py3-none-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting pygame==2.1.3.dev8\n",
      "  Downloading pygame-2.1.3.dev8-cp38-cp38-win_amd64.whl (10.6 MB)\n",
      "     -------------------------------------- 10.6/10.6 MB 578.3 kB/s eta 0:00:00\n",
      "Collecting box2d-py==2.3.5\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
      "     -------------------------------------- 374.4/374.4 kB 1.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\p2100788\\.conda\\envs\\gpu_env\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium[box2d]) (3.10.0)\n",
      "Building wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py): started\n",
      "  Building wheel for box2d-py (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for box2d-py\n",
      "Failed to build box2d-py\n",
      "Installing collected packages: swig, box2d-py, pygame\n",
      "  Running setup.py install for box2d-py: started\n",
      "  Running setup.py install for box2d-py: finished with status 'done'\n",
      "Successfully installed box2d-py-2.3.5 pygame-2.1.3.dev8 swig-4.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [16 lines of output]\n",
      "      Using setuptools (version 65.5.0).\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-38\n",
      "      creating build\\lib.win-amd64-cpython-38\\Box2D\n",
      "      copying library\\Box2D\\Box2D.py -> build\\lib.win-amd64-cpython-38\\Box2D\n",
      "      copying library\\Box2D\\__init__.py -> build\\lib.win-amd64-cpython-38\\Box2D\n",
      "      creating build\\lib.win-amd64-cpython-38\\Box2D\\b2\n",
      "      copying library\\Box2D\\b2\\__init__.py -> build\\lib.win-amd64-cpython-38\\Box2D\\b2\n",
      "      running build_ext\n",
      "      building 'Box2D._Box2D' extension\n",
      "      swigging Box2D\\Box2D.i to Box2D\\Box2D_wrap.cpp\n",
      "      swig.exe -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\\Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\\Box2D_wrap.cpp Box2D\\Box2D.i\n",
      "      error: command 'swig.exe' failed: None\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for box2d-py\n",
      "  DEPRECATION: box2d-py was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import wandb\n",
    "import gymnasium as gym\n",
    "from models.dueling_dql import DuelingDQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\p2100788/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login 5f71bc6f91cdaa551a70e88cf2522fcc1425d29b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtimothyckl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\p2100788\\Downloads\\Reinforcement-Learning-CA2\\wandb\\run-20230126_103438-b109vn85</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/timothyckl/lunar-lander-rl/runs/b109vn85\" target=\"_blank\">glowing-fuse-56</a></strong> to <a href=\"https://wandb.ai/timothyckl/lunar-lander-rl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/timothyckl/lunar-lander-rl\" target=\"_blank\">https://wandb.ai/timothyckl/lunar-lander-rl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/timothyckl/lunar-lander-rl/runs/b109vn85\" target=\"_blank\">https://wandb.ai/timothyckl/lunar-lander-rl/runs/b109vn85</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/timothyckl/lunar-lander-rl/runs/b109vn85?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1fdeabace50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2', continuous=False, render_mode='rgb_array')\n",
    "learning_rate = 1e-3\n",
    "discount_factor = 0.99\n",
    "exploration_rate = 1.0\n",
    "episodes = 500\n",
    "max_steps = 1000\n",
    "\n",
    "wandb.init(project='lunar-lander-rl', entity='timothyckl', config={\n",
    "    'learning_rate': learning_rate,\n",
    "    'discount_factor': discount_factor,\n",
    "    'exploration_rate': exploration_rate,\n",
    "    'episodes': episodes,\n",
    "    'max_steps': max_steps\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EP 1/500] - Reward: 3.0451 - Steps: 157 - Eps: 0.0100 - Time: 11.87s\n",
      "[EP 2/500] - Reward: -275.7656 - Steps: 99 - Eps: 0.0100 - Time: 2.53s\n",
      "[EP 3/500] - Reward: -58.5352 - Steps: 169 - Eps: 0.0100 - Time: 4.26s\n",
      "[EP 4/500] - Reward: -380.3943 - Steps: 91 - Eps: 0.0100 - Time: 2.26s\n",
      "[EP 5/500] - Reward: -136.7215 - Steps: 289 - Eps: 0.0100 - Time: 7.42s\n",
      "[EP 6/500] - Reward: -317.5131 - Steps: 300 - Eps: 0.0100 - Time: 7.76s\n",
      "[EP 7/500] - Reward: -473.2359 - Steps: 127 - Eps: 0.0100 - Time: 3.23s\n",
      "[EP 8/500] - Reward: -249.2680 - Steps: 89 - Eps: 0.0100 - Time: 2.24s\n",
      "[EP 9/500] - Reward: -250.4681 - Steps: 203 - Eps: 0.0100 - Time: 5.12s\n",
      "[EP 10/500] - Reward: -318.6959 - Steps: 151 - Eps: 0.0100 - Time: 3.83s\n",
      "[EP 11/500] - Reward: -543.3797 - Steps: 97 - Eps: 0.0100 - Time: 2.47s\n",
      "[EP 12/500] - Reward: -374.4968 - Steps: 142 - Eps: 0.0100 - Time: 3.56s\n",
      "[EP 13/500] - Reward: -30.7144 - Steps: 116 - Eps: 0.0100 - Time: 2.90s\n",
      "[EP 14/500] - Reward: -349.8854 - Steps: 103 - Eps: 0.0100 - Time: 2.59s\n",
      "[EP 15/500] - Reward: -221.1889 - Steps: 715 - Eps: 0.0100 - Time: 18.19s\n",
      "[EP 16/500] - Reward: -370.9913 - Steps: 78 - Eps: 0.0100 - Time: 2.05s\n",
      "[EP 17/500] - Reward: -147.9496 - Steps: 502 - Eps: 0.0100 - Time: 13.44s\n",
      "[EP 18/500] - Reward: -34.2664 - Steps: 106 - Eps: 0.0100 - Time: 2.82s\n",
      "[EP 19/500] - Reward: -228.9653 - Steps: 581 - Eps: 0.0100 - Time: 15.14s\n",
      "[EP 20/500] - Reward: -216.4456 - Steps: 581 - Eps: 0.0100 - Time: 15.01s\n",
      "[EP 21/500] - Reward: -106.2904 - Steps: 422 - Eps: 0.0100 - Time: 10.81s\n",
      "[EP 22/500] - Reward: -229.1222 - Steps: 191 - Eps: 0.0100 - Time: 4.91s\n",
      "[EP 23/500] - Reward: -138.8484 - Steps: 165 - Eps: 0.0100 - Time: 4.19s\n",
      "[EP 24/500] - Reward: -92.9379 - Steps: 168 - Eps: 0.0100 - Time: 4.28s\n",
      "[EP 25/500] - Reward: -85.9500 - Steps: 134 - Eps: 0.0100 - Time: 3.41s\n",
      "[EP 26/500] - Reward: -77.7313 - Steps: 83 - Eps: 0.0100 - Time: 2.11s\n",
      "[EP 27/500] - Reward: -274.0482 - Steps: 142 - Eps: 0.0100 - Time: 3.62s\n",
      "[EP 28/500] - Reward: -14.5825 - Steps: 112 - Eps: 0.0100 - Time: 2.81s\n",
      "[EP 29/500] - Reward: -180.8471 - Steps: 154 - Eps: 0.0100 - Time: 3.93s\n",
      "[EP 30/500] - Reward: -242.9728 - Steps: 102 - Eps: 0.0100 - Time: 2.57s\n",
      "[EP 31/500] - Reward: 38.9169 - Steps: 197 - Eps: 0.0100 - Time: 5.04s\n",
      "[EP 32/500] - Reward: -49.0686 - Steps: 141 - Eps: 0.0100 - Time: 3.58s\n",
      "[EP 33/500] - Reward: -284.3769 - Steps: 100 - Eps: 0.0100 - Time: 2.50s\n",
      "[EP 34/500] - Reward: -133.6815 - Steps: 143 - Eps: 0.0100 - Time: 3.60s\n",
      "[EP 35/500] - Reward: -343.4131 - Steps: 121 - Eps: 0.0100 - Time: 3.03s\n",
      "[EP 36/500] - Reward: -257.1688 - Steps: 97 - Eps: 0.0100 - Time: 2.46s\n",
      "[EP 37/500] - Reward: -308.6568 - Steps: 99 - Eps: 0.0100 - Time: 2.53s\n",
      "[EP 38/500] - Reward: -406.3892 - Steps: 131 - Eps: 0.0100 - Time: 3.42s\n",
      "[EP 39/500] - Reward: -264.8942 - Steps: 152 - Eps: 0.0100 - Time: 3.89s\n",
      "[EP 40/500] - Reward: -345.0757 - Steps: 92 - Eps: 0.0100 - Time: 2.36s\n",
      "[EP 41/500] - Reward: -334.7551 - Steps: 83 - Eps: 0.0100 - Time: 2.13s\n",
      "[EP 42/500] - Reward: -283.9057 - Steps: 131 - Eps: 0.0100 - Time: 3.34s\n",
      "[EP 43/500] - Reward: -226.3356 - Steps: 155 - Eps: 0.0100 - Time: 4.06s\n",
      "[EP 44/500] - Reward: -535.6553 - Steps: 121 - Eps: 0.0100 - Time: 3.14s\n",
      "[EP 45/500] - Reward: -480.0754 - Steps: 190 - Eps: 0.0100 - Time: 4.87s\n",
      "[EP 46/500] - Reward: -299.6326 - Steps: 122 - Eps: 0.0100 - Time: 3.13s\n",
      "[EP 47/500] - Reward: -265.5052 - Steps: 141 - Eps: 0.0100 - Time: 3.64s\n",
      "[EP 48/500] - Reward: -296.0122 - Steps: 117 - Eps: 0.0100 - Time: 3.05s\n",
      "[EP 49/500] - Reward: -259.3059 - Steps: 105 - Eps: 0.0100 - Time: 2.66s\n",
      "[EP 50/500] - Reward: -259.5556 - Steps: 236 - Eps: 0.0100 - Time: 6.01s\n",
      "[EP 51/500] - Reward: -320.1942 - Steps: 93 - Eps: 0.0100 - Time: 2.33s\n",
      "[EP 52/500] - Reward: -238.6165 - Steps: 139 - Eps: 0.0100 - Time: 3.58s\n",
      "[EP 53/500] - Reward: -278.4134 - Steps: 85 - Eps: 0.0100 - Time: 2.16s\n",
      "[EP 54/500] - Reward: -294.3021 - Steps: 87 - Eps: 0.0100 - Time: 2.18s\n",
      "[EP 55/500] - Reward: -279.3034 - Steps: 168 - Eps: 0.0100 - Time: 4.28s\n",
      "[EP 56/500] - Reward: -328.8334 - Steps: 112 - Eps: 0.0100 - Time: 2.90s\n",
      "[EP 57/500] - Reward: -172.6246 - Steps: 153 - Eps: 0.0100 - Time: 3.91s\n",
      "[EP 58/500] - Reward: -242.0623 - Steps: 178 - Eps: 0.0100 - Time: 4.59s\n",
      "[EP 59/500] - Reward: -98.2347 - Steps: 112 - Eps: 0.0100 - Time: 2.92s\n",
      "[EP 60/500] - Reward: -227.4063 - Steps: 219 - Eps: 0.0100 - Time: 5.65s\n",
      "[EP 61/500] - Reward: -254.1650 - Steps: 376 - Eps: 0.0100 - Time: 9.87s\n",
      "[EP 62/500] - Reward: -50.1290 - Steps: 235 - Eps: 0.0100 - Time: 6.11s\n",
      "[EP 63/500] - Reward: -135.9696 - Steps: 421 - Eps: 0.0100 - Time: 10.84s\n",
      "[EP 64/500] - Reward: -574.4484 - Steps: 666 - Eps: 0.0100 - Time: 16.94s\n",
      "[EP 65/500] - Reward: -204.8391 - Steps: 245 - Eps: 0.0100 - Time: 6.44s\n",
      "[EP 66/500] - Reward: -262.6501 - Steps: 529 - Eps: 0.0100 - Time: 14.05s\n",
      "[EP 67/500] - Reward: -137.7327 - Steps: 1000 - Eps: 0.0100 - Time: 25.66s\n",
      "[EP 68/500] - Reward: 216.4388 - Steps: 640 - Eps: 0.0100 - Time: 16.35s\n",
      "[EP 69/500] - Reward: -261.7918 - Steps: 289 - Eps: 0.0100 - Time: 7.47s\n",
      "[EP 70/500] - Reward: -109.2391 - Steps: 1000 - Eps: 0.0100 - Time: 25.89s\n",
      "[EP 71/500] - Reward: -85.5627 - Steps: 1000 - Eps: 0.0100 - Time: 25.76s\n",
      "[EP 72/500] - Reward: -90.8746 - Steps: 333 - Eps: 0.0100 - Time: 8.65s\n",
      "[EP 73/500] - Reward: -166.0756 - Steps: 162 - Eps: 0.0100 - Time: 4.26s\n",
      "[EP 74/500] - Reward: -50.6440 - Steps: 1000 - Eps: 0.0100 - Time: 26.08s\n",
      "[EP 75/500] - Reward: -93.3531 - Steps: 416 - Eps: 0.0100 - Time: 10.30s\n",
      "[EP 76/500] - Reward: -249.3626 - Steps: 772 - Eps: 0.0100 - Time: 19.02s\n",
      "[EP 77/500] - Reward: -115.4046 - Steps: 1000 - Eps: 0.0100 - Time: 25.31s\n",
      "[EP 78/500] - Reward: -130.5762 - Steps: 1000 - Eps: 0.0100 - Time: 25.38s\n",
      "[EP 79/500] - Reward: -94.5649 - Steps: 1000 - Eps: 0.0100 - Time: 26.06s\n",
      "[EP 80/500] - Reward: -16.4765 - Steps: 1000 - Eps: 0.0100 - Time: 25.52s\n",
      "[EP 81/500] - Reward: -58.8606 - Steps: 1000 - Eps: 0.0100 - Time: 26.15s\n",
      "[EP 82/500] - Reward: -12.7029 - Steps: 1000 - Eps: 0.0100 - Time: 26.16s\n",
      "[EP 83/500] - Reward: -60.5848 - Steps: 1000 - Eps: 0.0100 - Time: 25.80s\n",
      "[EP 84/500] - Reward: -74.5433 - Steps: 1000 - Eps: 0.0100 - Time: 25.72s\n",
      "[EP 85/500] - Reward: 4.0336 - Steps: 1000 - Eps: 0.0100 - Time: 25.59s\n",
      "[EP 86/500] - Reward: -642.5149 - Steps: 115 - Eps: 0.0100 - Time: 2.99s\n",
      "[EP 87/500] - Reward: -435.9836 - Steps: 121 - Eps: 0.0100 - Time: 3.01s\n",
      "[EP 88/500] - Reward: 278.6223 - Steps: 261 - Eps: 0.0100 - Time: 6.66s\n",
      "[EP 89/500] - Reward: -29.2663 - Steps: 105 - Eps: 0.0100 - Time: 2.69s\n",
      "[EP 90/500] - Reward: -32.7031 - Steps: 1000 - Eps: 0.0100 - Time: 25.88s\n",
      "[EP 91/500] - Reward: -29.4655 - Steps: 1000 - Eps: 0.0100 - Time: 26.08s\n",
      "[EP 92/500] - Reward: 271.0464 - Steps: 246 - Eps: 0.0100 - Time: 6.55s\n",
      "[EP 93/500] - Reward: -53.7623 - Steps: 403 - Eps: 0.0100 - Time: 10.38s\n",
      "[EP 94/500] - Reward: -93.9299 - Steps: 205 - Eps: 0.0100 - Time: 5.31s\n",
      "[EP 95/500] - Reward: -300.2201 - Steps: 234 - Eps: 0.0100 - Time: 6.04s\n",
      "[EP 96/500] - Reward: 3.7847 - Steps: 1000 - Eps: 0.0100 - Time: 25.67s\n",
      "[EP 97/500] - Reward: -40.8272 - Steps: 1000 - Eps: 0.0100 - Time: 25.48s\n",
      "[EP 98/500] - Reward: -53.3012 - Steps: 135 - Eps: 0.0100 - Time: 3.57s\n",
      "[EP 99/500] - Reward: 186.6414 - Steps: 508 - Eps: 0.0100 - Time: 13.14s\n",
      "[EP 100/500] - Reward: -22.8381 - Steps: 1000 - Eps: 0.0100 - Time: 39.70s\n",
      "[EP 101/500] - Reward: -40.1319 - Steps: 1000 - Eps: 0.0100 - Time: 25.30s\n",
      "[EP 102/500] - Reward: -380.9058 - Steps: 286 - Eps: 0.0100 - Time: 7.22s\n",
      "[EP 103/500] - Reward: -208.9530 - Steps: 237 - Eps: 0.0100 - Time: 5.96s\n",
      "[EP 104/500] - Reward: -274.3407 - Steps: 88 - Eps: 0.0100 - Time: 2.21s\n",
      "[EP 105/500] - Reward: -71.6789 - Steps: 248 - Eps: 0.0100 - Time: 6.24s\n",
      "[EP 106/500] - Reward: -353.2299 - Steps: 63 - Eps: 0.0100 - Time: 1.61s\n",
      "[EP 107/500] - Reward: 257.3451 - Steps: 474 - Eps: 0.0100 - Time: 12.02s\n",
      "[EP 108/500] - Reward: -163.4134 - Steps: 201 - Eps: 0.0100 - Time: 5.16s\n",
      "[EP 109/500] - Reward: -201.2420 - Steps: 196 - Eps: 0.0100 - Time: 4.99s\n",
      "[EP 110/500] - Reward: -217.5872 - Steps: 383 - Eps: 0.0100 - Time: 9.61s\n",
      "[EP 111/500] - Reward: -170.8712 - Steps: 204 - Eps: 0.0100 - Time: 5.14s\n",
      "[EP 112/500] - Reward: 249.1616 - Steps: 318 - Eps: 0.0100 - Time: 7.94s\n",
      "[EP 113/500] - Reward: 49.1410 - Steps: 189 - Eps: 0.0100 - Time: 4.92s\n",
      "[EP 114/500] - Reward: 216.3978 - Steps: 261 - Eps: 0.0100 - Time: 6.81s\n",
      "[EP 115/500] - Reward: -52.2796 - Steps: 128 - Eps: 0.0100 - Time: 3.30s\n",
      "[EP 116/500] - Reward: 249.2704 - Steps: 271 - Eps: 0.0100 - Time: 6.84s\n",
      "[EP 117/500] - Reward: -349.0856 - Steps: 125 - Eps: 0.0100 - Time: 3.15s\n",
      "[EP 118/500] - Reward: 291.4774 - Steps: 216 - Eps: 0.0100 - Time: 5.41s\n",
      "[EP 119/500] - Reward: -457.2171 - Steps: 84 - Eps: 0.0100 - Time: 2.10s\n",
      "[EP 120/500] - Reward: -317.8301 - Steps: 488 - Eps: 0.0100 - Time: 12.18s\n",
      "[EP 121/500] - Reward: 247.9757 - Steps: 326 - Eps: 0.0100 - Time: 8.20s\n",
      "[EP 122/500] - Reward: 252.5668 - Steps: 347 - Eps: 0.0100 - Time: 8.77s\n",
      "[EP 123/500] - Reward: -117.6108 - Steps: 144 - Eps: 0.0100 - Time: 3.63s\n",
      "[EP 124/500] - Reward: 268.9749 - Steps: 387 - Eps: 0.0100 - Time: 9.67s\n",
      "[EP 125/500] - Reward: 225.7232 - Steps: 707 - Eps: 0.0100 - Time: 17.70s\n",
      "[EP 126/500] - Reward: -139.7906 - Steps: 448 - Eps: 0.0100 - Time: 11.28s\n",
      "[EP 127/500] - Reward: -40.3178 - Steps: 1000 - Eps: 0.0100 - Time: 25.16s\n",
      "[EP 128/500] - Reward: 88.5680 - Steps: 1000 - Eps: 0.0100 - Time: 25.29s\n",
      "[EP 129/500] - Reward: -314.7813 - Steps: 385 - Eps: 0.0100 - Time: 9.81s\n",
      "[EP 130/500] - Reward: 273.0354 - Steps: 212 - Eps: 0.0100 - Time: 5.33s\n",
      "[EP 131/500] - Reward: 284.5668 - Steps: 247 - Eps: 0.0100 - Time: 6.18s\n",
      "[EP 132/500] - Reward: 304.4872 - Steps: 252 - Eps: 0.0100 - Time: 6.29s\n",
      "[EP 133/500] - Reward: 244.1735 - Steps: 587 - Eps: 0.0100 - Time: 14.79s\n",
      "[EP 134/500] - Reward: -30.2653 - Steps: 1000 - Eps: 0.0100 - Time: 25.32s\n",
      "[EP 135/500] - Reward: 178.4944 - Steps: 683 - Eps: 0.0100 - Time: 17.22s\n",
      "[EP 136/500] - Reward: 65.0401 - Steps: 1000 - Eps: 0.0100 - Time: 25.97s\n",
      "[EP 137/500] - Reward: 207.0258 - Steps: 222 - Eps: 0.0100 - Time: 5.60s\n",
      "[EP 138/500] - Reward: 114.3924 - Steps: 1000 - Eps: 0.0100 - Time: 25.04s\n",
      "[EP 139/500] - Reward: 224.1618 - Steps: 248 - Eps: 0.0100 - Time: 6.30s\n",
      "[EP 140/500] - Reward: 191.6472 - Steps: 491 - Eps: 0.0100 - Time: 12.52s\n",
      "[EP 141/500] - Reward: 186.4635 - Steps: 332 - Eps: 0.0100 - Time: 8.48s\n",
      "[EP 142/500] - Reward: 251.1472 - Steps: 563 - Eps: 0.0100 - Time: 14.28s\n",
      "[EP 143/500] - Reward: 207.2487 - Steps: 818 - Eps: 0.0100 - Time: 20.59s\n",
      "[EP 144/500] - Reward: 223.7371 - Steps: 417 - Eps: 0.0100 - Time: 10.57s\n",
      "[EP 145/500] - Reward: 227.3202 - Steps: 324 - Eps: 0.0100 - Time: 8.22s\n",
      "[EP 146/500] - Reward: 244.4386 - Steps: 693 - Eps: 0.0100 - Time: 17.58s\n",
      "[EP 147/500] - Reward: 263.6080 - Steps: 281 - Eps: 0.0100 - Time: 7.09s\n",
      "[EP 148/500] - Reward: 249.7065 - Steps: 338 - Eps: 0.0100 - Time: 8.47s\n",
      "[EP 149/500] - Reward: 247.2249 - Steps: 667 - Eps: 0.0100 - Time: 16.72s\n",
      "[EP 150/500] - Reward: 264.7229 - Steps: 277 - Eps: 0.0100 - Time: 7.03s\n",
      "[EP 151/500] - Reward: -155.4700 - Steps: 1000 - Eps: 0.0100 - Time: 25.22s\n",
      "[EP 152/500] - Reward: -79.8848 - Steps: 75 - Eps: 0.0100 - Time: 1.95s\n",
      "[EP 153/500] - Reward: 254.2574 - Steps: 473 - Eps: 0.0100 - Time: 11.90s\n",
      "[EP 154/500] - Reward: 209.2547 - Steps: 435 - Eps: 0.0100 - Time: 10.91s\n",
      "[EP 155/500] - Reward: -139.5348 - Steps: 528 - Eps: 0.0100 - Time: 13.54s\n",
      "[EP 156/500] - Reward: 230.2226 - Steps: 310 - Eps: 0.0100 - Time: 8.17s\n",
      "[EP 157/500] - Reward: -343.0463 - Steps: 212 - Eps: 0.0100 - Time: 5.50s\n",
      "[EP 158/500] - Reward: 257.0341 - Steps: 317 - Eps: 0.0100 - Time: 8.01s\n",
      "[EP 159/500] - Reward: -83.9607 - Steps: 100 - Eps: 0.0100 - Time: 2.50s\n",
      "[EP 160/500] - Reward: 195.5208 - Steps: 369 - Eps: 0.0100 - Time: 9.22s\n",
      "[EP 161/500] - Reward: 254.0548 - Steps: 298 - Eps: 0.0100 - Time: 7.48s\n",
      "[EP 162/500] - Reward: 220.0638 - Steps: 556 - Eps: 0.0100 - Time: 13.98s\n",
      "[EP 163/500] - Reward: 208.5792 - Steps: 479 - Eps: 0.0100 - Time: 12.26s\n",
      "[EP 164/500] - Reward: 279.4555 - Steps: 298 - Eps: 0.0100 - Time: 7.63s\n",
      "[EP 165/500] - Reward: 247.8156 - Steps: 299 - Eps: 0.0100 - Time: 7.61s\n",
      "[EP 166/500] - Reward: 244.4948 - Steps: 351 - Eps: 0.0100 - Time: 8.88s\n",
      "[EP 167/500] - Reward: 251.2112 - Steps: 398 - Eps: 0.0100 - Time: 9.99s\n",
      "[EP 168/500] - Reward: 245.2807 - Steps: 306 - Eps: 0.0100 - Time: 7.72s\n",
      "[EP 169/500] - Reward: 255.0601 - Steps: 248 - Eps: 0.0100 - Time: 6.24s\n",
      "[EP 170/500] - Reward: 239.8419 - Steps: 515 - Eps: 0.0100 - Time: 12.94s\n",
      "[EP 171/500] - Reward: -264.0923 - Steps: 527 - Eps: 0.0100 - Time: 13.40s\n",
      "[EP 172/500] - Reward: 225.6690 - Steps: 394 - Eps: 0.0100 - Time: 10.04s\n",
      "[EP 173/500] - Reward: -194.8543 - Steps: 467 - Eps: 0.0100 - Time: 11.75s\n",
      "[EP 174/500] - Reward: 245.2588 - Steps: 210 - Eps: 0.0100 - Time: 5.27s\n",
      "[EP 175/500] - Reward: 267.1904 - Steps: 322 - Eps: 0.0100 - Time: 8.07s\n",
      "[EP 176/500] - Reward: 278.2144 - Steps: 270 - Eps: 0.0100 - Time: 6.84s\n",
      "[EP 177/500] - Reward: 289.1002 - Steps: 286 - Eps: 0.0100 - Time: 7.20s\n",
      "[EP 178/500] - Reward: 270.1688 - Steps: 342 - Eps: 0.0100 - Time: 8.65s\n",
      "[EP 179/500] - Reward: 261.1704 - Steps: 306 - Eps: 0.0100 - Time: 7.80s\n",
      "[EP 180/500] - Reward: 270.3586 - Steps: 407 - Eps: 0.0100 - Time: 10.34s\n",
      "[EP 181/500] - Reward: 255.0741 - Steps: 254 - Eps: 0.0100 - Time: 6.41s\n",
      "[EP 182/500] - Reward: 262.7552 - Steps: 245 - Eps: 0.0100 - Time: 6.12s\n",
      "[EP 183/500] - Reward: 273.5938 - Steps: 267 - Eps: 0.0100 - Time: 6.61s\n",
      "[EP 184/500] - Reward: 243.4591 - Steps: 219 - Eps: 0.0100 - Time: 5.47s\n",
      "[EP 185/500] - Reward: 270.6558 - Steps: 238 - Eps: 0.0100 - Time: 6.15s\n",
      "[EP 186/500] - Reward: 288.0454 - Steps: 283 - Eps: 0.0100 - Time: 7.40s\n",
      "[EP 187/500] - Reward: 260.9622 - Steps: 219 - Eps: 0.0100 - Time: 5.63s\n",
      "[EP 188/500] - Reward: 282.4441 - Steps: 318 - Eps: 0.0100 - Time: 8.05s\n",
      "[EP 189/500] - Reward: 54.9547 - Steps: 197 - Eps: 0.0100 - Time: 4.95s\n",
      "[EP 190/500] - Reward: 284.1277 - Steps: 228 - Eps: 0.0100 - Time: 5.72s\n",
      "[EP 191/500] - Reward: 267.7342 - Steps: 268 - Eps: 0.0100 - Time: 6.68s\n",
      "[EP 192/500] - Reward: 292.3100 - Steps: 266 - Eps: 0.0100 - Time: 6.68s\n",
      "[EP 193/500] - Reward: 260.6626 - Steps: 229 - Eps: 0.0100 - Time: 5.71s\n",
      "[EP 194/500] - Reward: 276.7531 - Steps: 188 - Eps: 0.0100 - Time: 4.78s\n",
      "[EP 195/500] - Reward: 257.1320 - Steps: 248 - Eps: 0.0100 - Time: 6.31s\n",
      "[EP 196/500] - Reward: 288.9075 - Steps: 304 - Eps: 0.0100 - Time: 7.69s\n",
      "[EP 197/500] - Reward: 267.9315 - Steps: 314 - Eps: 0.0100 - Time: 7.98s\n",
      "[EP 198/500] - Reward: 261.3859 - Steps: 272 - Eps: 0.0100 - Time: 6.96s\n",
      "[EP 199/500] - Reward: 233.4631 - Steps: 224 - Eps: 0.0100 - Time: 5.74s\n",
      "[EP 200/500] - Reward: 263.3791 - Steps: 248 - Eps: 0.0100 - Time: 9.53s\n",
      "[EP 201/500] - Reward: 253.8570 - Steps: 187 - Eps: 0.0100 - Time: 4.84s\n",
      "[EP 202/500] - Reward: 293.8054 - Steps: 229 - Eps: 0.0100 - Time: 6.02s\n",
      "[EP 203/500] - Reward: 285.5353 - Steps: 343 - Eps: 0.0100 - Time: 9.00s\n",
      "[EP 204/500] - Reward: 250.2991 - Steps: 238 - Eps: 0.0100 - Time: 6.26s\n",
      "[EP 205/500] - Reward: 304.9482 - Steps: 282 - Eps: 0.0100 - Time: 7.33s\n",
      "[EP 206/500] - Reward: -146.4672 - Steps: 140 - Eps: 0.0100 - Time: 3.65s\n",
      "[EP 207/500] - Reward: 245.8534 - Steps: 223 - Eps: 0.0100 - Time: 5.80s\n",
      "[EP 208/500] - Reward: 278.1171 - Steps: 209 - Eps: 0.0100 - Time: 5.46s\n",
      "[EP 209/500] - Reward: 268.7232 - Steps: 259 - Eps: 0.0100 - Time: 6.71s\n",
      "[EP 210/500] - Reward: 286.1881 - Steps: 367 - Eps: 0.0100 - Time: 9.62s\n",
      "[EP 211/500] - Reward: 256.8245 - Steps: 200 - Eps: 0.0100 - Time: 5.22s\n",
      "[EP 212/500] - Reward: 274.0777 - Steps: 185 - Eps: 0.0100 - Time: 4.80s\n",
      "[EP 213/500] - Reward: 14.0159 - Steps: 234 - Eps: 0.0100 - Time: 6.13s\n",
      "[EP 214/500] - Reward: 271.6553 - Steps: 195 - Eps: 0.0100 - Time: 5.06s\n",
      "[EP 215/500] - Reward: 307.4891 - Steps: 217 - Eps: 0.0100 - Time: 5.74s\n",
      "[EP 216/500] - Reward: 17.7908 - Steps: 93 - Eps: 0.0100 - Time: 2.44s\n",
      "[EP 217/500] - Reward: 276.5238 - Steps: 250 - Eps: 0.0100 - Time: 6.53s\n",
      "[EP 218/500] - Reward: 310.9884 - Steps: 212 - Eps: 0.0100 - Time: 5.53s\n",
      "[EP 219/500] - Reward: 265.4635 - Steps: 335 - Eps: 0.0100 - Time: 8.79s\n",
      "[EP 220/500] - Reward: 248.4936 - Steps: 210 - Eps: 0.0100 - Time: 5.47s\n",
      "[EP 221/500] - Reward: 251.3965 - Steps: 186 - Eps: 0.0100 - Time: 4.87s\n",
      "[EP 222/500] - Reward: 279.6372 - Steps: 288 - Eps: 0.0100 - Time: 7.41s\n",
      "[EP 223/500] - Reward: 232.7875 - Steps: 196 - Eps: 0.0100 - Time: 5.15s\n",
      "[EP 224/500] - Reward: 276.4790 - Steps: 261 - Eps: 0.0100 - Time: 7.12s\n",
      "[EP 225/500] - Reward: 213.3105 - Steps: 472 - Eps: 0.0100 - Time: 12.47s\n",
      "[EP 226/500] - Reward: 259.3990 - Steps: 227 - Eps: 0.0100 - Time: 5.98s\n",
      "[EP 227/500] - Reward: 258.1862 - Steps: 243 - Eps: 0.0100 - Time: 6.33s\n",
      "[EP 228/500] - Reward: 20.9246 - Steps: 108 - Eps: 0.0100 - Time: 2.80s\n",
      "[EP 229/500] - Reward: 302.5397 - Steps: 256 - Eps: 0.0100 - Time: 6.71s\n",
      "[EP 230/500] - Reward: 237.1855 - Steps: 309 - Eps: 0.0100 - Time: 8.10s\n",
      "[EP 231/500] - Reward: 275.7154 - Steps: 258 - Eps: 0.0100 - Time: 6.83s\n",
      "[EP 232/500] - Reward: 278.2454 - Steps: 229 - Eps: 0.0100 - Time: 6.01s\n",
      "[EP 233/500] - Reward: 290.4070 - Steps: 226 - Eps: 0.0100 - Time: 5.93s\n",
      "[EP 234/500] - Reward: 204.1550 - Steps: 356 - Eps: 0.0100 - Time: 9.29s\n",
      "[EP 235/500] - Reward: -20.5074 - Steps: 86 - Eps: 0.0100 - Time: 2.25s\n",
      "[EP 236/500] - Reward: 41.2387 - Steps: 136 - Eps: 0.0100 - Time: 3.56s\n",
      "[EP 237/500] - Reward: 277.0601 - Steps: 188 - Eps: 0.0100 - Time: 4.93s\n",
      "[EP 238/500] - Reward: 248.1907 - Steps: 259 - Eps: 0.0100 - Time: 6.73s\n",
      "[EP 239/500] - Reward: 264.4151 - Steps: 206 - Eps: 0.0100 - Time: 5.38s\n",
      "[EP 240/500] - Reward: 257.1503 - Steps: 440 - Eps: 0.0100 - Time: 11.44s\n",
      "[EP 241/500] - Reward: 309.1005 - Steps: 248 - Eps: 0.0100 - Time: 6.44s\n",
      "[EP 242/500] - Reward: 301.7400 - Steps: 354 - Eps: 0.0100 - Time: 9.22s\n",
      "[EP 243/500] - Reward: 273.0181 - Steps: 319 - Eps: 0.0100 - Time: 8.28s\n",
      "[EP 244/500] - Reward: 310.5769 - Steps: 256 - Eps: 0.0100 - Time: 6.61s\n",
      "[EP 245/500] - Reward: 283.7008 - Steps: 228 - Eps: 0.0100 - Time: 5.88s\n",
      "[EP 246/500] - Reward: -38.5282 - Steps: 93 - Eps: 0.0100 - Time: 2.42s\n",
      "[EP 247/500] - Reward: 234.5554 - Steps: 416 - Eps: 0.0100 - Time: 10.75s\n",
      "[EP 248/500] - Reward: 239.8903 - Steps: 364 - Eps: 0.0100 - Time: 9.52s\n",
      "[EP 249/500] - Reward: 265.2986 - Steps: 276 - Eps: 0.0100 - Time: 7.22s\n",
      "[EP 250/500] - Reward: 204.6048 - Steps: 487 - Eps: 0.0100 - Time: 12.71s\n",
      "[EP 251/500] - Reward: 283.2128 - Steps: 257 - Eps: 0.0100 - Time: 6.72s\n",
      "[EP 252/500] - Reward: 250.2590 - Steps: 214 - Eps: 0.0100 - Time: 5.60s\n",
      "[EP 253/500] - Reward: 275.8871 - Steps: 207 - Eps: 0.0100 - Time: 5.41s\n",
      "[EP 254/500] - Reward: 244.0547 - Steps: 303 - Eps: 0.0100 - Time: 7.93s\n",
      "[EP 255/500] - Reward: 261.3170 - Steps: 328 - Eps: 0.0100 - Time: 8.63s\n",
      "[EP 256/500] - Reward: 280.1981 - Steps: 187 - Eps: 0.0100 - Time: 4.89s\n",
      "[EP 257/500] - Reward: 240.9420 - Steps: 229 - Eps: 0.0100 - Time: 5.95s\n",
      "[EP 258/500] - Reward: 259.3248 - Steps: 268 - Eps: 0.0100 - Time: 7.03s\n",
      "[EP 259/500] - Reward: 268.8816 - Steps: 247 - Eps: 0.0100 - Time: 6.56s\n",
      "[EP 260/500] - Reward: 265.0458 - Steps: 241 - Eps: 0.0100 - Time: 6.16s\n",
      "[EP 261/500] - Reward: -13.2328 - Steps: 151 - Eps: 0.0100 - Time: 3.95s\n",
      "[EP 262/500] - Reward: 278.2942 - Steps: 211 - Eps: 0.0100 - Time: 5.50s\n",
      "[EP 263/500] - Reward: 275.4966 - Steps: 241 - Eps: 0.0100 - Time: 6.24s\n",
      "[EP 264/500] - Reward: 254.0495 - Steps: 219 - Eps: 0.0100 - Time: 5.67s\n",
      "[EP 265/500] - Reward: 301.5033 - Steps: 234 - Eps: 0.0100 - Time: 6.15s\n",
      "[EP 266/500] - Reward: 267.6747 - Steps: 233 - Eps: 0.0100 - Time: 6.10s\n",
      "[EP 267/500] - Reward: 276.2424 - Steps: 201 - Eps: 0.0100 - Time: 5.25s\n",
      "[EP 268/500] - Reward: 17.6610 - Steps: 151 - Eps: 0.0100 - Time: 3.95s\n",
      "[EP 269/500] - Reward: 279.0475 - Steps: 236 - Eps: 0.0100 - Time: 6.18s\n",
      "[EP 270/500] - Reward: 232.9895 - Steps: 252 - Eps: 0.0100 - Time: 6.62s\n",
      "[EP 271/500] - Reward: 254.0415 - Steps: 260 - Eps: 0.0100 - Time: 6.72s\n",
      "[EP 272/500] - Reward: 252.9306 - Steps: 303 - Eps: 0.0100 - Time: 7.89s\n",
      "[EP 273/500] - Reward: 280.6225 - Steps: 225 - Eps: 0.0100 - Time: 5.92s\n",
      "[EP 274/500] - Reward: 269.3813 - Steps: 298 - Eps: 0.0100 - Time: 7.74s\n",
      "[EP 275/500] - Reward: 242.9787 - Steps: 310 - Eps: 0.0100 - Time: 8.13s\n",
      "[EP 276/500] - Reward: 250.2296 - Steps: 283 - Eps: 0.0100 - Time: 7.57s\n",
      "[EP 277/500] - Reward: 259.5094 - Steps: 259 - Eps: 0.0100 - Time: 6.79s\n",
      "[EP 278/500] - Reward: 291.1107 - Steps: 259 - Eps: 0.0100 - Time: 6.73s\n",
      "[EP 279/500] - Reward: 231.8341 - Steps: 239 - Eps: 0.0100 - Time: 6.37s\n",
      "[EP 280/500] - Reward: 236.5445 - Steps: 223 - Eps: 0.0100 - Time: 5.80s\n",
      "[EP 281/500] - Reward: 248.1803 - Steps: 341 - Eps: 0.0100 - Time: 9.01s\n",
      "[EP 282/500] - Reward: 305.7535 - Steps: 214 - Eps: 0.0100 - Time: 5.61s\n",
      "[EP 283/500] - Reward: 261.8168 - Steps: 236 - Eps: 0.0100 - Time: 6.14s\n",
      "[EP 284/500] - Reward: -157.5812 - Steps: 97 - Eps: 0.0100 - Time: 2.54s\n",
      "[EP 285/500] - Reward: 27.3590 - Steps: 100 - Eps: 0.0100 - Time: 2.61s\n",
      "[EP 286/500] - Reward: 268.3225 - Steps: 230 - Eps: 0.0100 - Time: 5.98s\n",
      "[EP 287/500] - Reward: 229.5483 - Steps: 493 - Eps: 0.0100 - Time: 12.73s\n",
      "[EP 288/500] - Reward: 272.6989 - Steps: 253 - Eps: 0.0100 - Time: 6.57s\n",
      "[EP 289/500] - Reward: 223.6083 - Steps: 318 - Eps: 0.0100 - Time: 8.22s\n",
      "[EP 290/500] - Reward: -2.7186 - Steps: 145 - Eps: 0.0100 - Time: 3.76s\n",
      "[EP 291/500] - Reward: 259.9913 - Steps: 239 - Eps: 0.0100 - Time: 6.25s\n",
      "[EP 292/500] - Reward: 270.0692 - Steps: 376 - Eps: 0.0100 - Time: 9.80s\n",
      "[EP 293/500] - Reward: 248.5665 - Steps: 303 - Eps: 0.0100 - Time: 8.22s\n",
      "[EP 294/500] - Reward: 273.8335 - Steps: 231 - Eps: 0.0100 - Time: 6.08s\n",
      "[EP 295/500] - Reward: 266.5447 - Steps: 305 - Eps: 0.0100 - Time: 7.97s\n",
      "[EP 296/500] - Reward: 245.5687 - Steps: 272 - Eps: 0.0100 - Time: 7.10s\n",
      "[EP 297/500] - Reward: 254.6261 - Steps: 367 - Eps: 0.0100 - Time: 9.50s\n",
      "[EP 298/500] - Reward: 260.4299 - Steps: 290 - Eps: 0.0100 - Time: 7.50s\n",
      "[EP 299/500] - Reward: 212.4818 - Steps: 300 - Eps: 0.0100 - Time: 7.78s\n",
      "[EP 300/500] - Reward: 266.8336 - Steps: 378 - Eps: 0.0100 - Time: 15.03s\n",
      "[EP 301/500] - Reward: 225.5901 - Steps: 311 - Eps: 0.0100 - Time: 8.08s\n",
      "[EP 302/500] - Reward: 206.4164 - Steps: 444 - Eps: 0.0100 - Time: 11.59s\n",
      "[EP 303/500] - Reward: 275.5307 - Steps: 265 - Eps: 0.0100 - Time: 6.83s\n",
      "[EP 304/500] - Reward: 256.3238 - Steps: 307 - Eps: 0.0100 - Time: 7.92s\n",
      "[EP 305/500] - Reward: 231.9796 - Steps: 245 - Eps: 0.0100 - Time: 6.28s\n",
      "[EP 306/500] - Reward: 251.9018 - Steps: 242 - Eps: 0.0100 - Time: 6.15s\n",
      "[EP 307/500] - Reward: 264.6827 - Steps: 210 - Eps: 0.0100 - Time: 5.36s\n",
      "[EP 308/500] - Reward: 272.1286 - Steps: 213 - Eps: 0.0100 - Time: 5.47s\n",
      "[EP 309/500] - Reward: 302.6470 - Steps: 239 - Eps: 0.0100 - Time: 6.15s\n",
      "[EP 310/500] - Reward: 263.5582 - Steps: 312 - Eps: 0.0100 - Time: 8.09s\n",
      "[EP 311/500] - Reward: 262.6493 - Steps: 239 - Eps: 0.0100 - Time: 6.24s\n",
      "[EP 312/500] - Reward: 271.7571 - Steps: 251 - Eps: 0.0100 - Time: 6.51s\n",
      "[EP 313/500] - Reward: 271.9806 - Steps: 474 - Eps: 0.0100 - Time: 12.18s\n",
      "[EP 314/500] - Reward: 274.1300 - Steps: 280 - Eps: 0.0100 - Time: 7.17s\n",
      "[EP 315/500] - Reward: 284.8580 - Steps: 338 - Eps: 0.0100 - Time: 8.71s\n",
      "[EP 316/500] - Reward: 276.5663 - Steps: 174 - Eps: 0.0100 - Time: 4.48s\n",
      "[EP 317/500] - Reward: 266.4637 - Steps: 277 - Eps: 0.0100 - Time: 7.16s\n",
      "[EP 318/500] - Reward: 270.0494 - Steps: 270 - Eps: 0.0100 - Time: 7.03s\n",
      "[EP 319/500] - Reward: 278.2206 - Steps: 262 - Eps: 0.0100 - Time: 6.81s\n",
      "[EP 320/500] - Reward: 249.5616 - Steps: 240 - Eps: 0.0100 - Time: 6.25s\n",
      "[EP 321/500] - Reward: 265.3374 - Steps: 257 - Eps: 0.0100 - Time: 6.64s\n",
      "[EP 322/500] - Reward: 261.8628 - Steps: 223 - Eps: 0.0100 - Time: 5.73s\n",
      "[EP 323/500] - Reward: 271.4096 - Steps: 231 - Eps: 0.0100 - Time: 5.94s\n",
      "[EP 324/500] - Reward: 242.6033 - Steps: 245 - Eps: 0.0100 - Time: 6.52s\n",
      "[EP 325/500] - Reward: 278.3864 - Steps: 252 - Eps: 0.0100 - Time: 6.82s\n",
      "[EP 326/500] - Reward: 270.6455 - Steps: 234 - Eps: 0.0100 - Time: 6.21s\n",
      "[EP 327/500] - Reward: 277.9114 - Steps: 186 - Eps: 0.0100 - Time: 4.83s\n",
      "[EP 328/500] - Reward: 262.8034 - Steps: 213 - Eps: 0.0100 - Time: 5.47s\n",
      "[EP 329/500] - Reward: 274.3628 - Steps: 219 - Eps: 0.0100 - Time: 5.69s\n",
      "[EP 330/500] - Reward: 275.8085 - Steps: 236 - Eps: 0.0100 - Time: 6.04s\n",
      "[EP 331/500] - Reward: 308.3637 - Steps: 298 - Eps: 0.0100 - Time: 7.64s\n",
      "[EP 332/500] - Reward: 13.0911 - Steps: 155 - Eps: 0.0100 - Time: 4.00s\n",
      "[EP 333/500] - Reward: 257.0013 - Steps: 281 - Eps: 0.0100 - Time: 7.21s\n",
      "[EP 334/500] - Reward: 262.3286 - Steps: 416 - Eps: 0.0100 - Time: 10.74s\n",
      "[EP 335/500] - Reward: 271.5406 - Steps: 388 - Eps: 0.0100 - Time: 10.03s\n",
      "[EP 336/500] - Reward: 255.5135 - Steps: 345 - Eps: 0.0100 - Time: 8.87s\n",
      "[EP 337/500] - Reward: 241.6661 - Steps: 193 - Eps: 0.0100 - Time: 4.93s\n",
      "[EP 338/500] - Reward: 0.9595 - Steps: 240 - Eps: 0.0100 - Time: 6.09s\n",
      "[EP 339/500] - Reward: 268.1900 - Steps: 243 - Eps: 0.0100 - Time: 6.19s\n",
      "[EP 340/500] - Reward: 231.5888 - Steps: 205 - Eps: 0.0100 - Time: 5.20s\n",
      "[EP 341/500] - Reward: 279.9902 - Steps: 241 - Eps: 0.0100 - Time: 6.06s\n",
      "[EP 342/500] - Reward: 265.1334 - Steps: 185 - Eps: 0.0100 - Time: 4.69s\n",
      "[EP 343/500] - Reward: 286.2467 - Steps: 286 - Eps: 0.0100 - Time: 7.24s\n",
      "[EP 344/500] - Reward: 269.7072 - Steps: 273 - Eps: 0.0100 - Time: 6.98s\n",
      "[EP 345/500] - Reward: 283.0688 - Steps: 263 - Eps: 0.0100 - Time: 6.78s\n",
      "[EP 346/500] - Reward: 293.0092 - Steps: 207 - Eps: 0.0100 - Time: 5.28s\n",
      "[EP 347/500] - Reward: 287.3642 - Steps: 212 - Eps: 0.0100 - Time: 5.41s\n",
      "[EP 348/500] - Reward: 244.4664 - Steps: 213 - Eps: 0.0100 - Time: 5.43s\n",
      "[EP 349/500] - Reward: 280.3093 - Steps: 348 - Eps: 0.0100 - Time: 8.88s\n",
      "[EP 350/500] - Reward: 237.3579 - Steps: 209 - Eps: 0.0100 - Time: 5.35s\n",
      "[EP 351/500] - Reward: 258.5723 - Steps: 198 - Eps: 0.0100 - Time: 5.07s\n",
      "[EP 352/500] - Reward: 281.0369 - Steps: 214 - Eps: 0.0100 - Time: 5.52s\n",
      "[EP 353/500] - Reward: -227.7906 - Steps: 195 - Eps: 0.0100 - Time: 5.00s\n",
      "[EP 354/500] - Reward: 288.1989 - Steps: 274 - Eps: 0.0100 - Time: 7.10s\n",
      "[EP 355/500] - Reward: 281.5225 - Steps: 211 - Eps: 0.0100 - Time: 5.38s\n",
      "[EP 356/500] - Reward: 44.1712 - Steps: 268 - Eps: 0.0100 - Time: 6.90s\n",
      "[EP 357/500] - Reward: 242.0085 - Steps: 298 - Eps: 0.0100 - Time: 7.64s\n",
      "[EP 358/500] - Reward: 199.0513 - Steps: 685 - Eps: 0.0100 - Time: 17.68s\n",
      "[EP 359/500] - Reward: 178.9559 - Steps: 559 - Eps: 0.0100 - Time: 15.01s\n",
      "[EP 360/500] - Reward: 304.5609 - Steps: 244 - Eps: 0.0100 - Time: 6.49s\n",
      "[EP 361/500] - Reward: 6.3887 - Steps: 1000 - Eps: 0.0100 - Time: 25.93s\n",
      "[EP 362/500] - Reward: 275.3833 - Steps: 190 - Eps: 0.0100 - Time: 4.99s\n",
      "[EP 363/500] - Reward: 41.4903 - Steps: 134 - Eps: 0.0100 - Time: 3.49s\n",
      "[EP 364/500] - Reward: 252.8681 - Steps: 205 - Eps: 0.0100 - Time: 5.29s\n",
      "[EP 365/500] - Reward: 264.1980 - Steps: 233 - Eps: 0.0100 - Time: 6.07s\n",
      "[EP 366/500] - Reward: 279.2641 - Steps: 205 - Eps: 0.0100 - Time: 5.32s\n",
      "[EP 367/500] - Reward: 179.0806 - Steps: 332 - Eps: 0.0100 - Time: 8.64s\n",
      "[EP 368/500] - Reward: 253.0028 - Steps: 310 - Eps: 0.0100 - Time: 8.10s\n",
      "[EP 369/500] - Reward: 282.3962 - Steps: 257 - Eps: 0.0100 - Time: 6.64s\n",
      "[EP 370/500] - Reward: 242.3748 - Steps: 200 - Eps: 0.0100 - Time: 5.09s\n",
      "[EP 371/500] - Reward: 140.4570 - Steps: 884 - Eps: 0.0100 - Time: 22.86s\n",
      "[EP 372/500] - Reward: 278.5773 - Steps: 177 - Eps: 0.0100 - Time: 4.64s\n",
      "[EP 373/500] - Reward: 205.4126 - Steps: 495 - Eps: 0.0100 - Time: 12.83s\n",
      "[EP 374/500] - Reward: 273.4841 - Steps: 277 - Eps: 0.0100 - Time: 7.29s\n",
      "[EP 375/500] - Reward: 295.0730 - Steps: 270 - Eps: 0.0100 - Time: 7.13s\n",
      "[EP 376/500] - Reward: 245.6040 - Steps: 225 - Eps: 0.0100 - Time: 5.89s\n",
      "[EP 377/500] - Reward: 283.1966 - Steps: 203 - Eps: 0.0100 - Time: 5.25s\n",
      "[EP 378/500] - Reward: 280.2638 - Steps: 217 - Eps: 0.0100 - Time: 5.66s\n",
      "[EP 379/500] - Reward: 254.7829 - Steps: 248 - Eps: 0.0100 - Time: 6.45s\n",
      "[EP 380/500] - Reward: 248.5818 - Steps: 193 - Eps: 0.0100 - Time: 5.02s\n",
      "[EP 381/500] - Reward: 194.7821 - Steps: 519 - Eps: 0.0100 - Time: 13.57s\n",
      "[EP 382/500] - Reward: 269.3212 - Steps: 188 - Eps: 0.0100 - Time: 4.98s\n",
      "[EP 383/500] - Reward: 243.4272 - Steps: 194 - Eps: 0.0100 - Time: 5.04s\n",
      "[EP 384/500] - Reward: 311.3973 - Steps: 199 - Eps: 0.0100 - Time: 5.19s\n",
      "[EP 385/500] - Reward: 279.8892 - Steps: 280 - Eps: 0.0100 - Time: 7.27s\n",
      "[EP 386/500] - Reward: 320.2425 - Steps: 223 - Eps: 0.0100 - Time: 5.83s\n",
      "[EP 387/500] - Reward: 285.1264 - Steps: 247 - Eps: 0.0100 - Time: 6.36s\n",
      "[EP 388/500] - Reward: 302.0058 - Steps: 212 - Eps: 0.0100 - Time: 5.51s\n",
      "[EP 389/500] - Reward: 219.3507 - Steps: 324 - Eps: 0.0100 - Time: 8.64s\n",
      "[EP 390/500] - Reward: 264.8954 - Steps: 220 - Eps: 0.0100 - Time: 5.92s\n",
      "[EP 391/500] - Reward: 194.5787 - Steps: 484 - Eps: 0.0100 - Time: 12.78s\n",
      "[EP 392/500] - Reward: 269.4128 - Steps: 213 - Eps: 0.0100 - Time: 5.60s\n",
      "[EP 393/500] - Reward: 298.6955 - Steps: 305 - Eps: 0.0100 - Time: 7.98s\n",
      "[EP 394/500] - Reward: 287.2817 - Steps: 213 - Eps: 0.0100 - Time: 5.60s\n",
      "[EP 395/500] - Reward: 8.6848 - Steps: 119 - Eps: 0.0100 - Time: 3.10s\n",
      "[EP 396/500] - Reward: 216.1137 - Steps: 611 - Eps: 0.0100 - Time: 15.94s\n",
      "[EP 397/500] - Reward: 275.8692 - Steps: 252 - Eps: 0.0100 - Time: 6.60s\n",
      "[EP 398/500] - Reward: 252.3229 - Steps: 242 - Eps: 0.0100 - Time: 6.29s\n",
      "[EP 399/500] - Reward: 255.0082 - Steps: 272 - Eps: 0.0100 - Time: 7.02s\n",
      "[EP 400/500] - Reward: -13.4915 - Steps: 161 - Eps: 0.0100 - Time: 6.48s\n",
      "[EP 401/500] - Reward: 259.2722 - Steps: 292 - Eps: 0.0100 - Time: 7.54s\n",
      "[EP 402/500] - Reward: 13.7501 - Steps: 101 - Eps: 0.0100 - Time: 2.61s\n",
      "[EP 403/500] - Reward: 274.9843 - Steps: 207 - Eps: 0.0100 - Time: 5.32s\n",
      "[EP 404/500] - Reward: 34.3003 - Steps: 151 - Eps: 0.0100 - Time: 3.90s\n",
      "[EP 405/500] - Reward: 277.0649 - Steps: 192 - Eps: 0.0100 - Time: 4.92s\n",
      "[EP 406/500] - Reward: 32.1671 - Steps: 135 - Eps: 0.0100 - Time: 3.51s\n",
      "[EP 407/500] - Reward: 309.4549 - Steps: 265 - Eps: 0.0100 - Time: 6.77s\n",
      "[EP 408/500] - Reward: 276.5676 - Steps: 212 - Eps: 0.0100 - Time: 5.49s\n",
      "[EP 409/500] - Reward: 8.0268 - Steps: 169 - Eps: 0.0100 - Time: 4.40s\n",
      "[EP 410/500] - Reward: 286.5645 - Steps: 251 - Eps: 0.0100 - Time: 6.53s\n",
      "[EP 411/500] - Reward: -60.3231 - Steps: 258 - Eps: 0.0100 - Time: 6.68s\n",
      "[EP 412/500] - Reward: -63.8685 - Steps: 104 - Eps: 0.0100 - Time: 2.72s\n",
      "[EP 413/500] - Reward: 261.0155 - Steps: 250 - Eps: 0.0100 - Time: 6.53s\n",
      "[EP 414/500] - Reward: 233.4221 - Steps: 271 - Eps: 0.0100 - Time: 7.03s\n",
      "[EP 415/500] - Reward: 263.2742 - Steps: 303 - Eps: 0.0100 - Time: 7.92s\n",
      "[EP 416/500] - Reward: 254.1554 - Steps: 255 - Eps: 0.0100 - Time: 6.72s\n",
      "[EP 417/500] - Reward: -243.1085 - Steps: 137 - Eps: 0.0100 - Time: 3.60s\n",
      "[EP 418/500] - Reward: -448.9485 - Steps: 132 - Eps: 0.0100 - Time: 3.43s\n",
      "[EP 419/500] - Reward: -175.0305 - Steps: 155 - Eps: 0.0100 - Time: 4.00s\n",
      "[EP 420/500] - Reward: 240.8708 - Steps: 329 - Eps: 0.0100 - Time: 8.62s\n",
      "[EP 421/500] - Reward: 289.2313 - Steps: 292 - Eps: 0.0100 - Time: 7.59s\n",
      "[EP 422/500] - Reward: 269.5707 - Steps: 297 - Eps: 0.0100 - Time: 7.74s\n",
      "[EP 423/500] - Reward: 251.4228 - Steps: 329 - Eps: 0.0100 - Time: 8.58s\n",
      "[EP 424/500] - Reward: 260.7656 - Steps: 305 - Eps: 0.0100 - Time: 7.88s\n",
      "[EP 425/500] - Reward: 299.6284 - Steps: 283 - Eps: 0.0100 - Time: 7.34s\n",
      "[EP 426/500] - Reward: 219.8502 - Steps: 206 - Eps: 0.0100 - Time: 5.60s\n",
      "[EP 427/500] - Reward: -131.2118 - Steps: 58 - Eps: 0.0100 - Time: 1.56s\n",
      "[EP 428/500] - Reward: -290.5506 - Steps: 258 - Eps: 0.0100 - Time: 6.87s\n",
      "[EP 429/500] - Reward: 268.6567 - Steps: 231 - Eps: 0.0100 - Time: 5.98s\n",
      "[EP 430/500] - Reward: 276.7670 - Steps: 318 - Eps: 0.0100 - Time: 8.27s\n",
      "[EP 431/500] - Reward: 319.7992 - Steps: 223 - Eps: 0.0100 - Time: 5.73s\n",
      "[EP 432/500] - Reward: 268.0571 - Steps: 254 - Eps: 0.0100 - Time: 6.54s\n",
      "[EP 433/500] - Reward: 260.4703 - Steps: 333 - Eps: 0.0100 - Time: 8.63s\n",
      "[EP 434/500] - Reward: -41.8964 - Steps: 155 - Eps: 0.0100 - Time: 4.01s\n",
      "[EP 435/500] - Reward: 69.3261 - Steps: 157 - Eps: 0.0100 - Time: 3.98s\n",
      "[EP 436/500] - Reward: 260.7356 - Steps: 259 - Eps: 0.0100 - Time: 6.70s\n",
      "[EP 437/500] - Reward: 242.7959 - Steps: 433 - Eps: 0.0100 - Time: 11.33s\n",
      "[EP 438/500] - Reward: 23.9660 - Steps: 150 - Eps: 0.0100 - Time: 3.94s\n",
      "[EP 439/500] - Reward: -67.0624 - Steps: 98 - Eps: 0.0100 - Time: 2.55s\n",
      "[EP 440/500] - Reward: 244.0273 - Steps: 591 - Eps: 0.0100 - Time: 15.21s\n",
      "[EP 441/500] - Reward: 241.7355 - Steps: 274 - Eps: 0.0100 - Time: 7.08s\n",
      "[EP 442/500] - Reward: -50.6377 - Steps: 87 - Eps: 0.0100 - Time: 2.24s\n",
      "[EP 443/500] - Reward: -340.4190 - Steps: 222 - Eps: 0.0100 - Time: 5.68s\n",
      "[EP 444/500] - Reward: 253.0859 - Steps: 304 - Eps: 0.0100 - Time: 7.77s\n",
      "[EP 445/500] - Reward: 149.6148 - Steps: 942 - Eps: 0.0100 - Time: 24.24s\n",
      "[EP 446/500] - Reward: -337.9653 - Steps: 193 - Eps: 0.0100 - Time: 5.07s\n",
      "[EP 447/500] - Reward: -292.4697 - Steps: 85 - Eps: 0.0100 - Time: 2.19s\n",
      "[EP 448/500] - Reward: -98.0584 - Steps: 211 - Eps: 0.0100 - Time: 5.43s\n",
      "[EP 449/500] - Reward: -84.8643 - Steps: 204 - Eps: 0.0100 - Time: 5.30s\n",
      "[EP 450/500] - Reward: -266.7753 - Steps: 89 - Eps: 0.0100 - Time: 2.32s\n",
      "[EP 451/500] - Reward: -55.1233 - Steps: 79 - Eps: 0.0100 - Time: 2.04s\n",
      "[EP 452/500] - Reward: -65.2293 - Steps: 217 - Eps: 0.0100 - Time: 5.58s\n",
      "[EP 453/500] - Reward: -203.2482 - Steps: 137 - Eps: 0.0100 - Time: 3.53s\n",
      "[EP 454/500] - Reward: -188.4458 - Steps: 76 - Eps: 0.0100 - Time: 1.95s\n",
      "[EP 455/500] - Reward: -97.3607 - Steps: 77 - Eps: 0.0100 - Time: 1.96s\n",
      "[EP 456/500] - Reward: -53.2976 - Steps: 95 - Eps: 0.0100 - Time: 2.43s\n",
      "[EP 457/500] - Reward: -261.9369 - Steps: 229 - Eps: 0.0100 - Time: 5.95s\n",
      "[EP 458/500] - Reward: -67.8234 - Steps: 152 - Eps: 0.0100 - Time: 3.96s\n",
      "[EP 459/500] - Reward: 7.5685 - Steps: 203 - Eps: 0.0100 - Time: 5.26s\n",
      "[EP 460/500] - Reward: -248.7088 - Steps: 210 - Eps: 0.0100 - Time: 5.47s\n",
      "[EP 461/500] - Reward: -52.2903 - Steps: 269 - Eps: 0.0100 - Time: 6.95s\n",
      "[EP 462/500] - Reward: -118.2658 - Steps: 137 - Eps: 0.0100 - Time: 3.53s\n",
      "[EP 463/500] - Reward: -23.1400 - Steps: 109 - Eps: 0.0100 - Time: 2.81s\n",
      "[EP 464/500] - Reward: -171.2460 - Steps: 139 - Eps: 0.0100 - Time: 3.57s\n",
      "[EP 465/500] - Reward: -76.2627 - Steps: 97 - Eps: 0.0100 - Time: 2.48s\n",
      "[EP 466/500] - Reward: 238.2405 - Steps: 310 - Eps: 0.0100 - Time: 7.96s\n",
      "[EP 467/500] - Reward: -132.3960 - Steps: 146 - Eps: 0.0100 - Time: 3.80s\n",
      "[EP 468/500] - Reward: -271.2419 - Steps: 250 - Eps: 0.0100 - Time: 6.56s\n",
      "[EP 469/500] - Reward: 254.0682 - Steps: 413 - Eps: 0.0100 - Time: 11.13s\n",
      "[EP 470/500] - Reward: -227.0099 - Steps: 280 - Eps: 0.0100 - Time: 7.33s\n",
      "[EP 471/500] - Reward: 234.9292 - Steps: 219 - Eps: 0.0100 - Time: 5.64s\n",
      "[EP 472/500] - Reward: -66.0093 - Steps: 331 - Eps: 0.0100 - Time: 8.55s\n",
      "[EP 473/500] - Reward: -264.0154 - Steps: 373 - Eps: 0.0100 - Time: 9.70s\n",
      "[EP 474/500] - Reward: -91.3557 - Steps: 171 - Eps: 0.0100 - Time: 4.52s\n",
      "[EP 475/500] - Reward: 226.2709 - Steps: 280 - Eps: 0.0100 - Time: 7.31s\n",
      "[EP 476/500] - Reward: -241.0278 - Steps: 166 - Eps: 0.0100 - Time: 4.36s\n",
      "[EP 477/500] - Reward: -128.0978 - Steps: 190 - Eps: 0.0100 - Time: 4.99s\n",
      "[EP 478/500] - Reward: 274.5502 - Steps: 310 - Eps: 0.0100 - Time: 8.10s\n",
      "[EP 479/500] - Reward: 281.3300 - Steps: 226 - Eps: 0.0100 - Time: 5.81s\n",
      "[EP 480/500] - Reward: -127.6271 - Steps: 337 - Eps: 0.0100 - Time: 8.69s\n",
      "[EP 481/500] - Reward: -211.5502 - Steps: 198 - Eps: 0.0100 - Time: 5.14s\n",
      "[EP 482/500] - Reward: 175.7142 - Steps: 785 - Eps: 0.0100 - Time: 20.09s\n",
      "[EP 483/500] - Reward: -156.4698 - Steps: 531 - Eps: 0.0100 - Time: 13.68s\n",
      "[EP 484/500] - Reward: 291.2704 - Steps: 287 - Eps: 0.0100 - Time: 7.47s\n",
      "[EP 485/500] - Reward: 228.7262 - Steps: 376 - Eps: 0.0100 - Time: 9.82s\n",
      "[EP 486/500] - Reward: 236.7026 - Steps: 284 - Eps: 0.0100 - Time: 7.40s\n",
      "[EP 487/500] - Reward: 247.4681 - Steps: 367 - Eps: 0.0100 - Time: 9.58s\n",
      "[EP 488/500] - Reward: 198.1017 - Steps: 414 - Eps: 0.0100 - Time: 10.70s\n",
      "[EP 489/500] - Reward: -248.3197 - Steps: 221 - Eps: 0.0100 - Time: 5.68s\n",
      "[EP 490/500] - Reward: 235.2534 - Steps: 363 - Eps: 0.0100 - Time: 9.35s\n",
      "[EP 491/500] - Reward: 256.5074 - Steps: 418 - Eps: 0.0100 - Time: 10.94s\n",
      "[EP 492/500] - Reward: 278.1954 - Steps: 366 - Eps: 0.0100 - Time: 9.52s\n",
      "[EP 493/500] - Reward: 243.7834 - Steps: 325 - Eps: 0.0100 - Time: 8.45s\n",
      "[EP 494/500] - Reward: 269.8061 - Steps: 277 - Eps: 0.0100 - Time: 7.13s\n",
      "[EP 495/500] - Reward: -190.9012 - Steps: 237 - Eps: 0.0100 - Time: 6.10s\n",
      "[EP 496/500] - Reward: 262.7103 - Steps: 405 - Eps: 0.0100 - Time: 10.58s\n",
      "[EP 497/500] - Reward: 260.9938 - Steps: 328 - Eps: 0.0100 - Time: 8.83s\n",
      "[EP 498/500] - Reward: 253.4176 - Steps: 400 - Eps: 0.0100 - Time: 10.47s\n",
      "[EP 499/500] - Reward: 263.2579 - Steps: 335 - Eps: 0.0100 - Time: 8.56s\n",
      "[EP 500/500] - Reward: 266.6862 - Steps: 326 - Eps: 0.0100 - Time: 12.82s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epsilon</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>reward</td><td>▃▃▅▃▄▁▅█▃█▆▇▇▇███████▆▇▇██▆████▇█▇█▅▄▅██</td></tr><tr><td>steps</td><td>▁▁▁▁▁▅█▂▁▂█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▅▂▃▂▂▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epsilon</td><td>0.01</td></tr><tr><td>reward</td><td>266.68616</td></tr><tr><td>steps</td><td>326</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-fuse-56</strong> at: <a href=\"https://wandb.ai/timothyckl/lunar-lander-rl/runs/b109vn85\" target=\"_blank\">https://wandb.ai/timothyckl/lunar-lander-rl/runs/b109vn85</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230126_103438-b109vn85\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: assets/dueling_dqn\\assets\n"
     ]
    }
   ],
   "source": [
    "agent = DuelingDQL(env, learning_rate, discount_factor, exploration_rate)\n",
    "history = agent.train(episodes, max_steps, log_wandb=True, update=True, save_episodes=True, save_interval=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test agent\n",
    "# history = agent.train(10, 1000, log_wandb=False, update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "# if not os.path.exists('./history'):\n",
    "#         os.mkdir('./history')\n",
    "\n",
    "# with open('./history/dueling_dql_history.json', 'w') as file:\n",
    "#     json.dump(history, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ab940f376b527f66a4e49bb4b86f8a630000a78bb1dead571560376c16ae2f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
