{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15c2f2c",
   "metadata": {},
   "source": [
    "# Deep Q-Learning (DQL) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea04686c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T07:10:57.885906Z",
     "iopub.status.busy": "2023-01-25T07:10:57.885589Z",
     "iopub.status.idle": "2023-01-25T07:11:07.188694Z",
     "shell.execute_reply": "2023-01-25T07:11:07.187472Z"
    },
    "papermill": {
     "duration": 9.311761,
     "end_time": "2023-01-25T07:11:07.191579",
     "exception": false,
     "start_time": "2023-01-25T07:10:57.879818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import wandb\n",
    "import gymnasium as gym\n",
    "from models.dql import DQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a26f0d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "829c7789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T07:11:09.700514Z",
     "iopub.status.busy": "2023-01-25T07:11:09.699483Z",
     "iopub.status.idle": "2023-01-25T07:11:16.992782Z",
     "shell.execute_reply": "2023-01-25T07:11:16.991263Z"
    },
    "papermill": {
     "duration": 7.303986,
     "end_time": "2023-01-25T07:11:16.997697",
     "exception": false,
     "start_time": "2023-01-25T07:11:09.693711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtimothyckl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230125_071110-3308mhhj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/timothyckl/lunar-lander-rl/runs/3308mhhj\" target=\"_blank\">beaming-ox-46</a></strong> to <a href=\"https://wandb.ai/timothyckl/lunar-lander-rl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/timothyckl/lunar-lander-rl/runs/3308mhhj?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbe42322250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2', continuous=False, render_mode='rgb_array')\n",
    "learning_rate = 0.0005\n",
    "discount_factor = 0.99\n",
    "exploration_rate = 1.0\n",
    "episodes = 500\n",
    "max_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc56cbae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T07:11:17.060345Z",
     "iopub.status.busy": "2023-01-25T07:11:17.059730Z",
     "iopub.status.idle": "2023-01-25T15:24:07.818024Z",
     "shell.execute_reply": "2023-01-25T15:24:07.817125Z"
    },
    "papermill": {
     "duration": 29570.791373,
     "end_time": "2023-01-25T15:24:07.820049",
     "exception": false,
     "start_time": "2023-01-25T07:11:17.028676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EP 1/500] - Reward: -386.2785 - Steps: 83 - Eps: 0.8262 - Time: 10.62s\n",
      "[EP 2/500] - Reward: -274.8717 - Steps: 95 - Eps: 0.3180 - Time: 19.94s\n",
      "[EP 3/500] - Reward: -121.5796 - Steps: 94 - Eps: 0.1236 - Time: 18.52s\n",
      "[EP 4/500] - Reward: -290.6719 - Steps: 224 - Eps: 0.0130 - Time: 35.23s\n",
      "[EP 5/500] - Reward: -252.3756 - Steps: 252 - Eps: 0.0100 - Time: 40.64s\n",
      "[EP 6/500] - Reward: -314.1560 - Steps: 73 - Eps: 0.0100 - Time: 11.79s\n",
      "[EP 7/500] - Reward: -325.5761 - Steps: 120 - Eps: 0.0100 - Time: 19.60s\n",
      "[EP 8/500] - Reward: -252.8616 - Steps: 102 - Eps: 0.0100 - Time: 15.83s\n",
      "[EP 9/500] - Reward: -175.2039 - Steps: 160 - Eps: 0.0100 - Time: 25.77s\n",
      "[EP 10/500] - Reward: -259.5435 - Steps: 330 - Eps: 0.0100 - Time: 53.46s\n",
      "[EP 11/500] - Reward: -323.0438 - Steps: 1000 - Eps: 0.0100 - Time: 160.07s\n",
      "[EP 12/500] - Reward: -357.7366 - Steps: 224 - Eps: 0.0100 - Time: 35.00s\n",
      "[EP 13/500] - Reward: -83.6096 - Steps: 245 - Eps: 0.0100 - Time: 38.80s\n",
      "[EP 14/500] - Reward: -94.4584 - Steps: 234 - Eps: 0.0100 - Time: 37.03s\n",
      "[EP 15/500] - Reward: -156.0804 - Steps: 1000 - Eps: 0.0100 - Time: 159.14s\n",
      "[EP 16/500] - Reward: -167.5508 - Steps: 1000 - Eps: 0.0100 - Time: 156.64s\n",
      "[EP 17/500] - Reward: -161.1680 - Steps: 1000 - Eps: 0.0100 - Time: 156.73s\n",
      "[EP 18/500] - Reward: -148.6150 - Steps: 1000 - Eps: 0.0100 - Time: 155.93s\n",
      "[EP 19/500] - Reward: -154.6680 - Steps: 1000 - Eps: 0.0100 - Time: 156.20s\n",
      "[EP 20/500] - Reward: -74.4838 - Steps: 1000 - Eps: 0.0100 - Time: 157.11s\n",
      "[EP 21/500] - Reward: -135.9274 - Steps: 1000 - Eps: 0.0100 - Time: 156.26s\n",
      "[EP 22/500] - Reward: -155.2375 - Steps: 163 - Eps: 0.0100 - Time: 25.31s\n",
      "[EP 23/500] - Reward: -84.0527 - Steps: 355 - Eps: 0.0100 - Time: 54.50s\n",
      "[EP 24/500] - Reward: -148.9149 - Steps: 524 - Eps: 0.0100 - Time: 80.95s\n",
      "[EP 25/500] - Reward: -108.4111 - Steps: 1000 - Eps: 0.0100 - Time: 154.01s\n",
      "[EP 26/500] - Reward: -134.6747 - Steps: 1000 - Eps: 0.0100 - Time: 154.83s\n",
      "[EP 27/500] - Reward: -107.0447 - Steps: 1000 - Eps: 0.0100 - Time: 154.94s\n",
      "[EP 28/500] - Reward: -62.8822 - Steps: 1000 - Eps: 0.0100 - Time: 154.59s\n",
      "[EP 29/500] - Reward: -283.3106 - Steps: 934 - Eps: 0.0100 - Time: 143.66s\n",
      "[EP 30/500] - Reward: 97.9783 - Steps: 869 - Eps: 0.0100 - Time: 134.49s\n",
      "[EP 31/500] - Reward: -45.2562 - Steps: 489 - Eps: 0.0100 - Time: 75.07s\n",
      "[EP 32/500] - Reward: 23.3360 - Steps: 375 - Eps: 0.0100 - Time: 57.81s\n",
      "[EP 33/500] - Reward: -104.8366 - Steps: 418 - Eps: 0.0100 - Time: 64.34s\n",
      "[EP 34/500] - Reward: -56.2722 - Steps: 1000 - Eps: 0.0100 - Time: 154.64s\n",
      "[EP 35/500] - Reward: -171.2370 - Steps: 598 - Eps: 0.0100 - Time: 92.03s\n",
      "[EP 36/500] - Reward: -174.1313 - Steps: 256 - Eps: 0.0100 - Time: 39.88s\n",
      "[EP 37/500] - Reward: -10.4832 - Steps: 1000 - Eps: 0.0100 - Time: 153.52s\n",
      "[EP 38/500] - Reward: -97.0259 - Steps: 366 - Eps: 0.0100 - Time: 56.35s\n",
      "[EP 39/500] - Reward: -71.7205 - Steps: 1000 - Eps: 0.0100 - Time: 154.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 08:10:38.451831: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EP 40/500] - Reward: -4.5265 - Steps: 1000 - Eps: 0.0100 - Time: 155.11s\n",
      "[EP 41/500] - Reward: -83.6642 - Steps: 180 - Eps: 0.0100 - Time: 27.74s\n",
      "[EP 42/500] - Reward: -85.6042 - Steps: 1000 - Eps: 0.0100 - Time: 154.32s\n",
      "[EP 43/500] - Reward: -87.8022 - Steps: 1000 - Eps: 0.0100 - Time: 153.37s\n",
      "[EP 44/500] - Reward: -69.8377 - Steps: 1000 - Eps: 0.0100 - Time: 153.32s\n",
      "[EP 45/500] - Reward: -125.7431 - Steps: 1000 - Eps: 0.0100 - Time: 153.07s\n",
      "[EP 46/500] - Reward: -28.8256 - Steps: 1000 - Eps: 0.0100 - Time: 153.98s\n",
      "[EP 47/500] - Reward: -2.8521 - Steps: 1000 - Eps: 0.0100 - Time: 154.56s\n",
      "[EP 48/500] - Reward: -269.7451 - Steps: 1000 - Eps: 0.0100 - Time: 153.26s\n",
      "[EP 49/500] - Reward: -66.8432 - Steps: 1000 - Eps: 0.0100 - Time: 153.91s\n",
      "[EP 50/500] - Reward: -12.6674 - Steps: 1000 - Eps: 0.0100 - Time: 153.04s\n",
      "[EP 51/500] - Reward: -24.7709 - Steps: 1000 - Eps: 0.0100 - Time: 155.13s\n",
      "[EP 52/500] - Reward: -64.6255 - Steps: 1000 - Eps: 0.0100 - Time: 152.68s\n",
      "[EP 53/500] - Reward: -43.4007 - Steps: 1000 - Eps: 0.0100 - Time: 153.90s\n",
      "[EP 54/500] - Reward: -27.1643 - Steps: 1000 - Eps: 0.0100 - Time: 153.60s\n",
      "[EP 55/500] - Reward: -13.1974 - Steps: 1000 - Eps: 0.0100 - Time: 152.60s\n",
      "[EP 56/500] - Reward: -15.3776 - Steps: 1000 - Eps: 0.0100 - Time: 152.47s\n",
      "[EP 57/500] - Reward: 16.6439 - Steps: 1000 - Eps: 0.0100 - Time: 152.43s\n",
      "[EP 58/500] - Reward: -27.5112 - Steps: 1000 - Eps: 0.0100 - Time: 151.75s\n",
      "[EP 59/500] - Reward: -62.2740 - Steps: 1000 - Eps: 0.0100 - Time: 152.63s\n",
      "[EP 60/500] - Reward: -43.6645 - Steps: 1000 - Eps: 0.0100 - Time: 152.70s\n",
      "[EP 61/500] - Reward: -61.2203 - Steps: 575 - Eps: 0.0100 - Time: 87.68s\n",
      "[EP 62/500] - Reward: -411.7712 - Steps: 99 - Eps: 0.0100 - Time: 14.58s\n",
      "[EP 63/500] - Reward: -13.9166 - Steps: 1000 - Eps: 0.0100 - Time: 153.50s\n",
      "[EP 64/500] - Reward: -55.5280 - Steps: 1000 - Eps: 0.0100 - Time: 152.53s\n",
      "[EP 65/500] - Reward: 48.6035 - Steps: 1000 - Eps: 0.0100 - Time: 153.77s\n",
      "[EP 66/500] - Reward: -67.5654 - Steps: 1000 - Eps: 0.0100 - Time: 152.65s\n",
      "[EP 67/500] - Reward: -65.5599 - Steps: 1000 - Eps: 0.0100 - Time: 153.80s\n",
      "[EP 68/500] - Reward: -271.1018 - Steps: 64 - Eps: 0.0100 - Time: 9.76s\n",
      "[EP 69/500] - Reward: -109.3618 - Steps: 1000 - Eps: 0.0100 - Time: 153.72s\n",
      "[EP 70/500] - Reward: -417.2875 - Steps: 143 - Eps: 0.0100 - Time: 22.33s\n",
      "[EP 71/500] - Reward: -68.2397 - Steps: 1000 - Eps: 0.0100 - Time: 154.76s\n",
      "[EP 72/500] - Reward: -28.2144 - Steps: 1000 - Eps: 0.0100 - Time: 154.33s\n",
      "[EP 73/500] - Reward: -1.4692 - Steps: 1000 - Eps: 0.0100 - Time: 154.17s\n",
      "[EP 74/500] - Reward: 198.2354 - Steps: 718 - Eps: 0.0100 - Time: 108.89s\n",
      "[EP 75/500] - Reward: -289.1850 - Steps: 378 - Eps: 0.0100 - Time: 57.88s\n",
      "[EP 76/500] - Reward: -296.8564 - Steps: 622 - Eps: 0.0100 - Time: 95.44s\n",
      "[EP 77/500] - Reward: -40.4222 - Steps: 251 - Eps: 0.0100 - Time: 38.18s\n",
      "[EP 78/500] - Reward: -104.9712 - Steps: 91 - Eps: 0.0100 - Time: 14.36s\n",
      "[EP 79/500] - Reward: -145.6194 - Steps: 517 - Eps: 0.0100 - Time: 78.52s\n",
      "[EP 80/500] - Reward: -50.2391 - Steps: 1000 - Eps: 0.0100 - Time: 153.65s\n",
      "[EP 81/500] - Reward: -17.4604 - Steps: 1000 - Eps: 0.0100 - Time: 154.56s\n",
      "[EP 82/500] - Reward: -77.3652 - Steps: 353 - Eps: 0.0100 - Time: 54.28s\n",
      "[EP 83/500] - Reward: 251.7341 - Steps: 609 - Eps: 0.0100 - Time: 93.88s\n",
      "[EP 84/500] - Reward: -147.0833 - Steps: 324 - Eps: 0.0100 - Time: 49.70s\n",
      "[EP 85/500] - Reward: -92.4502 - Steps: 270 - Eps: 0.0100 - Time: 42.16s\n",
      "[EP 86/500] - Reward: -128.1850 - Steps: 364 - Eps: 0.0100 - Time: 56.96s\n",
      "[EP 87/500] - Reward: -60.2760 - Steps: 1000 - Eps: 0.0100 - Time: 155.35s\n",
      "[EP 88/500] - Reward: -11.8415 - Steps: 1000 - Eps: 0.0100 - Time: 154.95s\n",
      "[EP 89/500] - Reward: 177.6242 - Steps: 938 - Eps: 0.0100 - Time: 143.59s\n",
      "[EP 90/500] - Reward: 186.8597 - Steps: 549 - Eps: 0.0100 - Time: 84.72s\n",
      "[EP 91/500] - Reward: 36.6591 - Steps: 1000 - Eps: 0.0100 - Time: 153.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 09:55:33.860067: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EP 92/500] - Reward: 215.6000 - Steps: 609 - Eps: 0.0100 - Time: 94.18s\n",
      "[EP 93/500] - Reward: -100.7444 - Steps: 300 - Eps: 0.0100 - Time: 46.30s\n",
      "[EP 94/500] - Reward: -76.7950 - Steps: 1000 - Eps: 0.0100 - Time: 153.86s\n",
      "[EP 95/500] - Reward: -65.8058 - Steps: 1000 - Eps: 0.0100 - Time: 154.61s\n",
      "[EP 96/500] - Reward: 236.0182 - Steps: 454 - Eps: 0.0100 - Time: 68.76s\n",
      "[EP 97/500] - Reward: -33.4589 - Steps: 240 - Eps: 0.0100 - Time: 36.57s\n",
      "[EP 98/500] - Reward: 168.3775 - Steps: 454 - Eps: 0.0100 - Time: 70.57s\n",
      "[EP 99/500] - Reward: -59.5977 - Steps: 153 - Eps: 0.0100 - Time: 22.78s\n",
      "[EP 100/500] - Reward: 268.3316 - Steps: 431 - Eps: 0.0100 - Time: 76.91s\n",
      "[EP 101/500] - Reward: 154.9822 - Steps: 663 - Eps: 0.0100 - Time: 101.78s\n",
      "[EP 102/500] - Reward: 40.8883 - Steps: 1000 - Eps: 0.0100 - Time: 153.23s\n",
      "[EP 103/500] - Reward: -139.6758 - Steps: 150 - Eps: 0.0100 - Time: 22.97s\n",
      "[EP 104/500] - Reward: 171.5342 - Steps: 754 - Eps: 0.0100 - Time: 115.31s\n",
      "[EP 105/500] - Reward: 216.6574 - Steps: 399 - Eps: 0.0100 - Time: 60.47s\n",
      "[EP 106/500] - Reward: 251.9307 - Steps: 325 - Eps: 0.0100 - Time: 49.63s\n",
      "[EP 107/500] - Reward: 198.3650 - Steps: 369 - Eps: 0.0100 - Time: 56.71s\n",
      "[EP 108/500] - Reward: 238.5183 - Steps: 627 - Eps: 0.0100 - Time: 96.30s\n",
      "[EP 109/500] - Reward: 176.4762 - Steps: 792 - Eps: 0.0100 - Time: 121.03s\n",
      "[EP 110/500] - Reward: 283.7302 - Steps: 481 - Eps: 0.0100 - Time: 73.95s\n",
      "[EP 111/500] - Reward: 183.5511 - Steps: 635 - Eps: 0.0100 - Time: 97.44s\n",
      "[EP 112/500] - Reward: 296.3547 - Steps: 465 - Eps: 0.0100 - Time: 70.55s\n",
      "[EP 113/500] - Reward: -89.6459 - Steps: 213 - Eps: 0.0100 - Time: 33.59s\n",
      "[EP 114/500] - Reward: 249.8461 - Steps: 322 - Eps: 0.0100 - Time: 48.54s\n",
      "[EP 115/500] - Reward: -98.8471 - Steps: 1000 - Eps: 0.0100 - Time: 152.67s\n",
      "[EP 116/500] - Reward: 252.1445 - Steps: 479 - Eps: 0.0100 - Time: 72.90s\n",
      "[EP 117/500] - Reward: 250.3164 - Steps: 574 - Eps: 0.0100 - Time: 88.35s\n",
      "[EP 118/500] - Reward: 220.3850 - Steps: 671 - Eps: 0.0100 - Time: 102.54s\n",
      "[EP 119/500] - Reward: 217.9007 - Steps: 405 - Eps: 0.0100 - Time: 61.47s\n",
      "[EP 120/500] - Reward: 260.6357 - Steps: 469 - Eps: 0.0100 - Time: 71.97s\n",
      "[EP 121/500] - Reward: 267.9944 - Steps: 431 - Eps: 0.0100 - Time: 64.73s\n",
      "[EP 122/500] - Reward: 226.8731 - Steps: 314 - Eps: 0.0100 - Time: 47.11s\n",
      "[EP 123/500] - Reward: 207.2530 - Steps: 604 - Eps: 0.0100 - Time: 92.63s\n",
      "[EP 124/500] - Reward: 266.3665 - Steps: 263 - Eps: 0.0100 - Time: 40.33s\n",
      "[EP 125/500] - Reward: 240.5662 - Steps: 547 - Eps: 0.0100 - Time: 83.55s\n",
      "[EP 126/500] - Reward: 240.8103 - Steps: 397 - Eps: 0.0100 - Time: 60.76s\n",
      "[EP 127/500] - Reward: 264.2233 - Steps: 390 - Eps: 0.0100 - Time: 59.81s\n",
      "[EP 128/500] - Reward: 43.5222 - Steps: 223 - Eps: 0.0100 - Time: 34.29s\n",
      "[EP 129/500] - Reward: -5.6920 - Steps: 108 - Eps: 0.0100 - Time: 16.34s\n",
      "[EP 130/500] - Reward: 29.7240 - Steps: 190 - Eps: 0.0100 - Time: 29.13s\n",
      "[EP 131/500] - Reward: 235.1752 - Steps: 711 - Eps: 0.0100 - Time: 107.67s\n",
      "[EP 132/500] - Reward: 238.5644 - Steps: 711 - Eps: 0.0100 - Time: 109.20s\n",
      "[EP 133/500] - Reward: 271.4211 - Steps: 507 - Eps: 0.0100 - Time: 77.45s\n",
      "[EP 134/500] - Reward: 195.0314 - Steps: 639 - Eps: 0.0100 - Time: 97.42s\n",
      "[EP 135/500] - Reward: 220.9887 - Steps: 731 - Eps: 0.0100 - Time: 112.05s\n",
      "[EP 136/500] - Reward: 232.5104 - Steps: 405 - Eps: 0.0100 - Time: 61.83s\n",
      "[EP 137/500] - Reward: 246.9343 - Steps: 326 - Eps: 0.0100 - Time: 49.40s\n",
      "[EP 138/500] - Reward: 242.0116 - Steps: 318 - Eps: 0.0100 - Time: 48.50s\n",
      "[EP 139/500] - Reward: 235.5632 - Steps: 310 - Eps: 0.0100 - Time: 47.11s\n",
      "[EP 140/500] - Reward: 233.1985 - Steps: 240 - Eps: 0.0100 - Time: 36.31s\n",
      "[EP 141/500] - Reward: 264.4149 - Steps: 344 - Eps: 0.0100 - Time: 52.09s\n",
      "[EP 142/500] - Reward: 251.6285 - Steps: 323 - Eps: 0.0100 - Time: 49.09s\n",
      "[EP 143/500] - Reward: 241.1966 - Steps: 474 - Eps: 0.0100 - Time: 72.26s\n",
      "[EP 144/500] - Reward: -243.1827 - Steps: 424 - Eps: 0.0100 - Time: 64.36s\n",
      "[EP 145/500] - Reward: -207.2559 - Steps: 344 - Eps: 0.0100 - Time: 52.09s\n",
      "[EP 146/500] - Reward: 175.9722 - Steps: 617 - Eps: 0.0100 - Time: 94.28s\n",
      "[EP 147/500] - Reward: 245.8330 - Steps: 351 - Eps: 0.0100 - Time: 53.26s\n",
      "[EP 148/500] - Reward: 254.4295 - Steps: 249 - Eps: 0.0100 - Time: 38.15s\n",
      "[EP 149/500] - Reward: 271.4994 - Steps: 303 - Eps: 0.0100 - Time: 45.83s\n",
      "[EP 150/500] - Reward: 138.8687 - Steps: 418 - Eps: 0.0100 - Time: 64.13s\n",
      "[EP 151/500] - Reward: 145.2349 - Steps: 759 - Eps: 0.0100 - Time: 115.22s\n",
      "[EP 152/500] - Reward: 269.6149 - Steps: 271 - Eps: 0.0100 - Time: 41.00s\n",
      "[EP 153/500] - Reward: 250.2645 - Steps: 233 - Eps: 0.0100 - Time: 35.60s\n",
      "[EP 154/500] - Reward: 248.0127 - Steps: 275 - Eps: 0.0100 - Time: 41.87s\n",
      "[EP 155/500] - Reward: 231.5760 - Steps: 550 - Eps: 0.0100 - Time: 83.46s\n",
      "[EP 156/500] - Reward: 234.3173 - Steps: 490 - Eps: 0.0100 - Time: 75.80s\n",
      "[EP 157/500] - Reward: 247.7828 - Steps: 357 - Eps: 0.0100 - Time: 54.75s\n",
      "[EP 158/500] - Reward: 41.7015 - Steps: 283 - Eps: 0.0100 - Time: 42.99s\n",
      "[EP 159/500] - Reward: 190.5188 - Steps: 568 - Eps: 0.0100 - Time: 86.93s\n",
      "[EP 160/500] - Reward: 268.7009 - Steps: 515 - Eps: 0.0100 - Time: 77.92s\n",
      "[EP 161/500] - Reward: 244.1442 - Steps: 251 - Eps: 0.0100 - Time: 38.47s\n",
      "[EP 162/500] - Reward: -187.6902 - Steps: 492 - Eps: 0.0100 - Time: 74.87s\n",
      "[EP 163/500] - Reward: 269.2000 - Steps: 287 - Eps: 0.0100 - Time: 43.60s\n",
      "[EP 164/500] - Reward: 277.1491 - Steps: 305 - Eps: 0.0100 - Time: 46.95s\n",
      "[EP 165/500] - Reward: 243.9642 - Steps: 287 - Eps: 0.0100 - Time: 43.27s\n",
      "[EP 166/500] - Reward: 214.7646 - Steps: 667 - Eps: 0.0100 - Time: 101.84s\n",
      "[EP 167/500] - Reward: 224.7188 - Steps: 290 - Eps: 0.0100 - Time: 44.96s\n",
      "[EP 168/500] - Reward: 226.2204 - Steps: 285 - Eps: 0.0100 - Time: 43.88s\n",
      "[EP 169/500] - Reward: -197.5746 - Steps: 958 - Eps: 0.0100 - Time: 146.46s\n",
      "[EP 170/500] - Reward: 270.6302 - Steps: 271 - Eps: 0.0100 - Time: 41.04s\n",
      "[EP 171/500] - Reward: 262.4919 - Steps: 304 - Eps: 0.0100 - Time: 46.65s\n",
      "[EP 172/500] - Reward: 272.4123 - Steps: 311 - Eps: 0.0100 - Time: 47.35s\n",
      "[EP 173/500] - Reward: 233.6209 - Steps: 252 - Eps: 0.0100 - Time: 38.75s\n",
      "[EP 174/500] - Reward: 262.3868 - Steps: 247 - Eps: 0.0100 - Time: 38.01s\n",
      "[EP 175/500] - Reward: 250.5375 - Steps: 216 - Eps: 0.0100 - Time: 33.07s\n",
      "[EP 176/500] - Reward: 231.3181 - Steps: 326 - Eps: 0.0100 - Time: 49.30s\n",
      "[EP 177/500] - Reward: 289.4421 - Steps: 270 - Eps: 0.0100 - Time: 41.52s\n",
      "[EP 178/500] - Reward: 243.6952 - Steps: 237 - Eps: 0.0100 - Time: 35.79s\n",
      "[EP 179/500] - Reward: 265.6853 - Steps: 333 - Eps: 0.0100 - Time: 50.38s\n",
      "[EP 180/500] - Reward: 234.4204 - Steps: 227 - Eps: 0.0100 - Time: 34.48s\n",
      "[EP 181/500] - Reward: 241.7414 - Steps: 201 - Eps: 0.0100 - Time: 30.27s\n",
      "[EP 182/500] - Reward: 266.6292 - Steps: 227 - Eps: 0.0100 - Time: 34.67s\n",
      "[EP 183/500] - Reward: 241.4740 - Steps: 207 - Eps: 0.0100 - Time: 31.86s\n",
      "[EP 184/500] - Reward: 288.4816 - Steps: 247 - Eps: 0.0100 - Time: 37.33s\n",
      "[EP 185/500] - Reward: 261.8456 - Steps: 318 - Eps: 0.0100 - Time: 47.70s\n",
      "[EP 186/500] - Reward: 268.1449 - Steps: 365 - Eps: 0.0100 - Time: 56.17s\n",
      "[EP 187/500] - Reward: 260.5563 - Steps: 279 - Eps: 0.0100 - Time: 42.54s\n",
      "[EP 188/500] - Reward: 260.5797 - Steps: 259 - Eps: 0.0100 - Time: 40.69s\n",
      "[EP 189/500] - Reward: 257.9980 - Steps: 187 - Eps: 0.0100 - Time: 28.90s\n",
      "[EP 190/500] - Reward: 292.7231 - Steps: 281 - Eps: 0.0100 - Time: 42.72s\n",
      "[EP 191/500] - Reward: 273.1545 - Steps: 308 - Eps: 0.0100 - Time: 47.65s\n",
      "[EP 192/500] - Reward: 227.2932 - Steps: 310 - Eps: 0.0100 - Time: 46.92s\n",
      "[EP 193/500] - Reward: 276.1543 - Steps: 306 - Eps: 0.0100 - Time: 46.99s\n",
      "[EP 194/500] - Reward: 231.8504 - Steps: 266 - Eps: 0.0100 - Time: 40.61s\n",
      "[EP 195/500] - Reward: 254.8922 - Steps: 256 - Eps: 0.0100 - Time: 39.48s\n",
      "[EP 196/500] - Reward: -42.8003 - Steps: 390 - Eps: 0.0100 - Time: 59.42s\n",
      "[EP 197/500] - Reward: 278.9619 - Steps: 291 - Eps: 0.0100 - Time: 44.18s\n",
      "[EP 198/500] - Reward: 271.6495 - Steps: 238 - Eps: 0.0100 - Time: 36.90s\n",
      "[EP 199/500] - Reward: 253.6074 - Steps: 178 - Eps: 0.0100 - Time: 26.91s\n",
      "[EP 200/500] - Reward: -18.2110 - Steps: 111 - Eps: 0.0100 - Time: 19.60s\n",
      "[EP 201/500] - Reward: -26.8509 - Steps: 108 - Eps: 0.0100 - Time: 16.49s\n",
      "[EP 202/500] - Reward: 254.5972 - Steps: 278 - Eps: 0.0100 - Time: 42.37s\n",
      "[EP 203/500] - Reward: 225.7298 - Steps: 394 - Eps: 0.0100 - Time: 60.29s\n",
      "[EP 204/500] - Reward: 147.3329 - Steps: 741 - Eps: 0.0100 - Time: 114.05s\n",
      "[EP 205/500] - Reward: 257.8862 - Steps: 259 - Eps: 0.0100 - Time: 38.95s\n",
      "[EP 206/500] - Reward: 232.3301 - Steps: 369 - Eps: 0.0100 - Time: 56.94s\n",
      "[EP 207/500] - Reward: 219.5346 - Steps: 782 - Eps: 0.0100 - Time: 119.46s\n",
      "[EP 208/500] - Reward: 250.6744 - Steps: 191 - Eps: 0.0100 - Time: 29.61s\n",
      "[EP 209/500] - Reward: 272.6605 - Steps: 245 - Eps: 0.0100 - Time: 38.38s\n",
      "[EP 210/500] - Reward: 247.2388 - Steps: 275 - Eps: 0.0100 - Time: 42.06s\n",
      "[EP 211/500] - Reward: 236.3874 - Steps: 302 - Eps: 0.0100 - Time: 46.30s\n",
      "[EP 212/500] - Reward: 269.0883 - Steps: 231 - Eps: 0.0100 - Time: 35.59s\n",
      "[EP 213/500] - Reward: 266.6852 - Steps: 227 - Eps: 0.0100 - Time: 34.80s\n",
      "[EP 214/500] - Reward: 280.3060 - Steps: 299 - Eps: 0.0100 - Time: 45.64s\n",
      "[EP 215/500] - Reward: 251.2183 - Steps: 258 - Eps: 0.0100 - Time: 39.77s\n",
      "[EP 216/500] - Reward: 249.0390 - Steps: 212 - Eps: 0.0100 - Time: 31.96s\n",
      "[EP 217/500] - Reward: 275.5339 - Steps: 288 - Eps: 0.0100 - Time: 44.21s\n",
      "[EP 218/500] - Reward: 285.1658 - Steps: 410 - Eps: 0.0100 - Time: 63.40s\n",
      "[EP 219/500] - Reward: 250.9477 - Steps: 264 - Eps: 0.0100 - Time: 40.24s\n",
      "[EP 220/500] - Reward: 261.4491 - Steps: 228 - Eps: 0.0100 - Time: 35.22s\n",
      "[EP 221/500] - Reward: 258.1538 - Steps: 214 - Eps: 0.0100 - Time: 32.17s\n",
      "[EP 222/500] - Reward: 242.6696 - Steps: 226 - Eps: 0.0100 - Time: 34.86s\n",
      "[EP 223/500] - Reward: 304.3079 - Steps: 208 - Eps: 0.0100 - Time: 32.32s\n",
      "[EP 224/500] - Reward: 235.8700 - Steps: 229 - Eps: 0.0100 - Time: 35.89s\n",
      "[EP 225/500] - Reward: 258.8724 - Steps: 248 - Eps: 0.0100 - Time: 37.64s\n",
      "[EP 226/500] - Reward: 288.6867 - Steps: 964 - Eps: 0.0100 - Time: 147.16s\n",
      "[EP 227/500] - Reward: 248.9232 - Steps: 181 - Eps: 0.0100 - Time: 27.45s\n",
      "[EP 228/500] - Reward: 237.7201 - Steps: 230 - Eps: 0.0100 - Time: 35.07s\n",
      "[EP 229/500] - Reward: 255.9578 - Steps: 740 - Eps: 0.0100 - Time: 113.02s\n",
      "[EP 230/500] - Reward: 270.4666 - Steps: 159 - Eps: 0.0100 - Time: 24.45s\n",
      "[EP 231/500] - Reward: 284.9790 - Steps: 276 - Eps: 0.0100 - Time: 41.23s\n",
      "[EP 232/500] - Reward: 282.0310 - Steps: 255 - Eps: 0.0100 - Time: 39.33s\n",
      "[EP 233/500] - Reward: 237.7330 - Steps: 218 - Eps: 0.0100 - Time: 33.53s\n",
      "[EP 234/500] - Reward: 246.6831 - Steps: 188 - Eps: 0.0100 - Time: 28.93s\n",
      "[EP 235/500] - Reward: 211.1448 - Steps: 338 - Eps: 0.0100 - Time: 51.09s\n",
      "[EP 236/500] - Reward: 251.6612 - Steps: 224 - Eps: 0.0100 - Time: 34.26s\n",
      "[EP 237/500] - Reward: 277.4146 - Steps: 256 - Eps: 0.0100 - Time: 39.89s\n",
      "[EP 238/500] - Reward: 258.4838 - Steps: 285 - Eps: 0.0100 - Time: 42.92s\n",
      "[EP 239/500] - Reward: 271.9816 - Steps: 257 - Eps: 0.0100 - Time: 39.06s\n",
      "[EP 240/500] - Reward: 261.8401 - Steps: 219 - Eps: 0.0100 - Time: 33.29s\n",
      "[EP 241/500] - Reward: 260.4791 - Steps: 189 - Eps: 0.0100 - Time: 29.05s\n",
      "[EP 242/500] - Reward: 297.1825 - Steps: 227 - Eps: 0.0100 - Time: 34.46s\n",
      "[EP 243/500] - Reward: 277.7439 - Steps: 259 - Eps: 0.0100 - Time: 39.99s\n",
      "[EP 244/500] - Reward: 298.0395 - Steps: 240 - Eps: 0.0100 - Time: 36.52s\n",
      "[EP 245/500] - Reward: 286.3944 - Steps: 254 - Eps: 0.0100 - Time: 38.64s\n",
      "[EP 246/500] - Reward: 295.8254 - Steps: 249 - Eps: 0.0100 - Time: 38.15s\n",
      "[EP 247/500] - Reward: 277.2762 - Steps: 260 - Eps: 0.0100 - Time: 39.52s\n",
      "[EP 248/500] - Reward: 268.0868 - Steps: 267 - Eps: 0.0100 - Time: 41.27s\n",
      "[EP 249/500] - Reward: 295.3491 - Steps: 264 - Eps: 0.0100 - Time: 39.91s\n",
      "[EP 250/500] - Reward: 293.8571 - Steps: 228 - Eps: 0.0100 - Time: 35.13s\n",
      "[EP 251/500] - Reward: 259.9955 - Steps: 279 - Eps: 0.0100 - Time: 43.12s\n",
      "[EP 252/500] - Reward: 264.6059 - Steps: 207 - Eps: 0.0100 - Time: 32.28s\n",
      "[EP 253/500] - Reward: 269.2566 - Steps: 284 - Eps: 0.0100 - Time: 43.30s\n",
      "[EP 254/500] - Reward: 297.1775 - Steps: 270 - Eps: 0.0100 - Time: 41.56s\n",
      "[EP 255/500] - Reward: 262.1217 - Steps: 308 - Eps: 0.0100 - Time: 47.97s\n",
      "[EP 256/500] - Reward: 306.5685 - Steps: 273 - Eps: 0.0100 - Time: 41.81s\n",
      "[EP 257/500] - Reward: 279.9247 - Steps: 215 - Eps: 0.0100 - Time: 32.59s\n",
      "[EP 258/500] - Reward: 256.0915 - Steps: 201 - Eps: 0.0100 - Time: 31.25s\n",
      "[EP 259/500] - Reward: 244.9328 - Steps: 243 - Eps: 0.0100 - Time: 37.33s\n",
      "[EP 260/500] - Reward: 272.4515 - Steps: 210 - Eps: 0.0100 - Time: 32.59s\n",
      "[EP 261/500] - Reward: 286.7091 - Steps: 214 - Eps: 0.0100 - Time: 32.53s\n",
      "[EP 262/500] - Reward: 286.3459 - Steps: 259 - Eps: 0.0100 - Time: 40.61s\n",
      "[EP 263/500] - Reward: 296.2892 - Steps: 238 - Eps: 0.0100 - Time: 36.47s\n",
      "[EP 264/500] - Reward: 272.7509 - Steps: 207 - Eps: 0.0100 - Time: 31.98s\n",
      "[EP 265/500] - Reward: 282.6326 - Steps: 298 - Eps: 0.0100 - Time: 45.33s\n",
      "[EP 266/500] - Reward: 276.6883 - Steps: 232 - Eps: 0.0100 - Time: 36.68s\n",
      "[EP 267/500] - Reward: 271.4003 - Steps: 204 - Eps: 0.0100 - Time: 31.08s\n",
      "[EP 268/500] - Reward: 278.2676 - Steps: 228 - Eps: 0.0100 - Time: 34.69s\n",
      "[EP 269/500] - Reward: 261.4282 - Steps: 178 - Eps: 0.0100 - Time: 28.01s\n",
      "[EP 270/500] - Reward: 259.8378 - Steps: 212 - Eps: 0.0100 - Time: 32.95s\n",
      "[EP 271/500] - Reward: 274.6921 - Steps: 281 - Eps: 0.0100 - Time: 43.67s\n",
      "[EP 272/500] - Reward: 273.9365 - Steps: 350 - Eps: 0.0100 - Time: 53.91s\n",
      "[EP 273/500] - Reward: 280.1408 - Steps: 241 - Eps: 0.0100 - Time: 37.16s\n",
      "[EP 274/500] - Reward: 297.8074 - Steps: 228 - Eps: 0.0100 - Time: 34.97s\n",
      "[EP 275/500] - Reward: 266.5625 - Steps: 233 - Eps: 0.0100 - Time: 36.23s\n",
      "[EP 276/500] - Reward: 253.7674 - Steps: 349 - Eps: 0.0100 - Time: 54.98s\n",
      "[EP 277/500] - Reward: 248.0069 - Steps: 192 - Eps: 0.0100 - Time: 29.63s\n",
      "[EP 278/500] - Reward: 276.6225 - Steps: 241 - Eps: 0.0100 - Time: 37.54s\n",
      "[EP 279/500] - Reward: 287.3923 - Steps: 261 - Eps: 0.0100 - Time: 40.84s\n",
      "[EP 280/500] - Reward: 286.5906 - Steps: 249 - Eps: 0.0100 - Time: 38.85s\n",
      "[EP 281/500] - Reward: 239.4057 - Steps: 204 - Eps: 0.0100 - Time: 31.73s\n",
      "[EP 282/500] - Reward: 237.1163 - Steps: 196 - Eps: 0.0100 - Time: 30.00s\n",
      "[EP 283/500] - Reward: 269.9744 - Steps: 219 - Eps: 0.0100 - Time: 33.84s\n",
      "[EP 284/500] - Reward: 237.0179 - Steps: 196 - Eps: 0.0100 - Time: 30.24s\n",
      "[EP 285/500] - Reward: 74.1302 - Steps: 239 - Eps: 0.0100 - Time: 36.77s\n",
      "[EP 286/500] - Reward: 279.4298 - Steps: 247 - Eps: 0.0100 - Time: 37.87s\n",
      "[EP 287/500] - Reward: 251.4595 - Steps: 226 - Eps: 0.0100 - Time: 34.95s\n",
      "[EP 288/500] - Reward: 285.9226 - Steps: 255 - Eps: 0.0100 - Time: 39.48s\n",
      "[EP 289/500] - Reward: 268.2447 - Steps: 324 - Eps: 0.0100 - Time: 50.51s\n",
      "[EP 290/500] - Reward: 292.8308 - Steps: 232 - Eps: 0.0100 - Time: 36.25s\n",
      "[EP 291/500] - Reward: 289.4929 - Steps: 262 - Eps: 0.0100 - Time: 41.15s\n",
      "[EP 292/500] - Reward: 269.9339 - Steps: 175 - Eps: 0.0100 - Time: 26.82s\n",
      "[EP 293/500] - Reward: 286.8779 - Steps: 253 - Eps: 0.0100 - Time: 40.05s\n",
      "[EP 294/500] - Reward: 59.2838 - Steps: 182 - Eps: 0.0100 - Time: 28.11s\n",
      "[EP 295/500] - Reward: 250.8765 - Steps: 583 - Eps: 0.0100 - Time: 90.63s\n",
      "[EP 296/500] - Reward: 272.3682 - Steps: 310 - Eps: 0.0100 - Time: 48.12s\n",
      "[EP 297/500] - Reward: 284.3967 - Steps: 293 - Eps: 0.0100 - Time: 44.34s\n",
      "[EP 298/500] - Reward: 242.6298 - Steps: 221 - Eps: 0.0100 - Time: 34.78s\n",
      "[EP 299/500] - Reward: 271.3750 - Steps: 193 - Eps: 0.0100 - Time: 29.79s\n",
      "[EP 300/500] - Reward: 259.1083 - Steps: 226 - Eps: 0.0100 - Time: 40.03s\n",
      "[EP 301/500] - Reward: 262.9364 - Steps: 456 - Eps: 0.0100 - Time: 69.02s\n",
      "[EP 302/500] - Reward: 263.1840 - Steps: 199 - Eps: 0.0100 - Time: 30.64s\n",
      "[EP 303/500] - Reward: 263.9799 - Steps: 296 - Eps: 0.0100 - Time: 45.13s\n",
      "[EP 304/500] - Reward: 264.9215 - Steps: 246 - Eps: 0.0100 - Time: 38.00s\n",
      "[EP 305/500] - Reward: 252.7124 - Steps: 246 - Eps: 0.0100 - Time: 37.93s\n",
      "[EP 306/500] - Reward: 214.5353 - Steps: 278 - Eps: 0.0100 - Time: 42.29s\n",
      "[EP 307/500] - Reward: 250.2653 - Steps: 303 - Eps: 0.0100 - Time: 47.08s\n",
      "[EP 308/500] - Reward: 252.9247 - Steps: 330 - Eps: 0.0100 - Time: 49.83s\n",
      "[EP 309/500] - Reward: 281.3141 - Steps: 227 - Eps: 0.0100 - Time: 34.71s\n",
      "[EP 310/500] - Reward: 248.2904 - Steps: 273 - Eps: 0.0100 - Time: 41.87s\n",
      "[EP 311/500] - Reward: 275.7269 - Steps: 192 - Eps: 0.0100 - Time: 29.19s\n",
      "[EP 312/500] - Reward: 291.6306 - Steps: 323 - Eps: 0.0100 - Time: 49.36s\n",
      "[EP 313/500] - Reward: 231.1716 - Steps: 258 - Eps: 0.0100 - Time: 39.45s\n",
      "[EP 314/500] - Reward: 261.5366 - Steps: 235 - Eps: 0.0100 - Time: 35.96s\n",
      "[EP 315/500] - Reward: 288.1961 - Steps: 275 - Eps: 0.0100 - Time: 42.30s\n",
      "[EP 316/500] - Reward: 302.9180 - Steps: 240 - Eps: 0.0100 - Time: 37.22s\n",
      "[EP 317/500] - Reward: 292.5869 - Steps: 299 - Eps: 0.0100 - Time: 46.12s\n",
      "[EP 318/500] - Reward: 280.5120 - Steps: 226 - Eps: 0.0100 - Time: 34.67s\n",
      "[EP 319/500] - Reward: 284.4036 - Steps: 197 - Eps: 0.0100 - Time: 30.62s\n",
      "[EP 320/500] - Reward: 264.8660 - Steps: 409 - Eps: 0.0100 - Time: 62.28s\n",
      "[EP 321/500] - Reward: 288.7342 - Steps: 279 - Eps: 0.0100 - Time: 42.89s\n",
      "[EP 322/500] - Reward: 238.8169 - Steps: 342 - Eps: 0.0100 - Time: 52.97s\n",
      "[EP 323/500] - Reward: 265.1567 - Steps: 290 - Eps: 0.0100 - Time: 44.17s\n",
      "[EP 324/500] - Reward: 295.4278 - Steps: 248 - Eps: 0.0100 - Time: 38.42s\n",
      "[EP 325/500] - Reward: 229.1213 - Steps: 218 - Eps: 0.0100 - Time: 33.66s\n",
      "[EP 326/500] - Reward: 259.9805 - Steps: 206 - Eps: 0.0100 - Time: 31.28s\n",
      "[EP 327/500] - Reward: 285.1634 - Steps: 241 - Eps: 0.0100 - Time: 36.50s\n",
      "[EP 328/500] - Reward: 277.5290 - Steps: 212 - Eps: 0.0100 - Time: 32.82s\n",
      "[EP 329/500] - Reward: 286.8837 - Steps: 217 - Eps: 0.0100 - Time: 33.48s\n",
      "[EP 330/500] - Reward: 265.5514 - Steps: 222 - Eps: 0.0100 - Time: 33.91s\n",
      "[EP 331/500] - Reward: 295.2558 - Steps: 282 - Eps: 0.0100 - Time: 43.09s\n",
      "[EP 332/500] - Reward: 106.1658 - Steps: 1000 - Eps: 0.0100 - Time: 153.28s\n",
      "[EP 333/500] - Reward: 249.3408 - Steps: 218 - Eps: 0.0100 - Time: 33.90s\n",
      "[EP 334/500] - Reward: 273.9536 - Steps: 166 - Eps: 0.0100 - Time: 25.66s\n",
      "[EP 335/500] - Reward: 293.4232 - Steps: 209 - Eps: 0.0100 - Time: 31.62s\n",
      "[EP 336/500] - Reward: 300.2743 - Steps: 196 - Eps: 0.0100 - Time: 30.29s\n",
      "[EP 337/500] - Reward: 232.8687 - Steps: 185 - Eps: 0.0100 - Time: 28.87s\n",
      "[EP 338/500] - Reward: 258.7681 - Steps: 221 - Eps: 0.0100 - Time: 33.67s\n",
      "[EP 339/500] - Reward: -99.1716 - Steps: 99 - Eps: 0.0100 - Time: 16.22s\n",
      "[EP 340/500] - Reward: 16.6306 - Steps: 139 - Eps: 0.0100 - Time: 20.96s\n",
      "[EP 341/500] - Reward: 261.2071 - Steps: 200 - Eps: 0.0100 - Time: 31.63s\n",
      "[EP 342/500] - Reward: 268.8917 - Steps: 305 - Eps: 0.0100 - Time: 46.75s\n",
      "[EP 343/500] - Reward: 251.7826 - Steps: 268 - Eps: 0.0100 - Time: 41.09s\n",
      "[EP 344/500] - Reward: 212.2513 - Steps: 440 - Eps: 0.0100 - Time: 67.51s\n",
      "[EP 345/500] - Reward: 252.2475 - Steps: 387 - Eps: 0.0100 - Time: 59.54s\n",
      "[EP 346/500] - Reward: 264.3346 - Steps: 262 - Eps: 0.0100 - Time: 40.26s\n",
      "[EP 347/500] - Reward: 63.7974 - Steps: 124 - Eps: 0.0100 - Time: 18.78s\n",
      "[EP 348/500] - Reward: 278.6329 - Steps: 204 - Eps: 0.0100 - Time: 31.49s\n",
      "[EP 349/500] - Reward: 297.4005 - Steps: 257 - Eps: 0.0100 - Time: 39.66s\n",
      "[EP 350/500] - Reward: 258.4917 - Steps: 207 - Eps: 0.0100 - Time: 32.27s\n",
      "[EP 351/500] - Reward: 277.6263 - Steps: 209 - Eps: 0.0100 - Time: 31.60s\n",
      "[EP 352/500] - Reward: 280.6266 - Steps: 222 - Eps: 0.0100 - Time: 35.04s\n",
      "[EP 353/500] - Reward: 275.7850 - Steps: 255 - Eps: 0.0100 - Time: 39.00s\n",
      "[EP 354/500] - Reward: -468.9653 - Steps: 96 - Eps: 0.0100 - Time: 14.57s\n",
      "[EP 355/500] - Reward: 274.6077 - Steps: 238 - Eps: 0.0100 - Time: 36.86s\n",
      "[EP 356/500] - Reward: -336.7220 - Steps: 278 - Eps: 0.0100 - Time: 43.19s\n",
      "[EP 357/500] - Reward: 237.8451 - Steps: 520 - Eps: 0.0100 - Time: 79.81s\n",
      "[EP 358/500] - Reward: 50.1509 - Steps: 102 - Eps: 0.0100 - Time: 15.91s\n",
      "[EP 359/500] - Reward: 210.0298 - Steps: 382 - Eps: 0.0100 - Time: 58.92s\n",
      "[EP 360/500] - Reward: 261.1888 - Steps: 334 - Eps: 0.0100 - Time: 50.94s\n",
      "[EP 361/500] - Reward: 255.4005 - Steps: 221 - Eps: 0.0100 - Time: 34.16s\n",
      "[EP 362/500] - Reward: 268.3698 - Steps: 320 - Eps: 0.0100 - Time: 49.45s\n",
      "[EP 363/500] - Reward: 257.8623 - Steps: 254 - Eps: 0.0100 - Time: 39.06s\n",
      "[EP 364/500] - Reward: 298.6804 - Steps: 305 - Eps: 0.0100 - Time: 47.44s\n",
      "[EP 365/500] - Reward: 286.1962 - Steps: 292 - Eps: 0.0100 - Time: 44.77s\n",
      "[EP 366/500] - Reward: 278.1649 - Steps: 241 - Eps: 0.0100 - Time: 37.32s\n",
      "[EP 367/500] - Reward: 248.4819 - Steps: 216 - Eps: 0.0100 - Time: 32.98s\n",
      "[EP 368/500] - Reward: 273.4860 - Steps: 251 - Eps: 0.0100 - Time: 39.21s\n",
      "[EP 369/500] - Reward: 264.5675 - Steps: 229 - Eps: 0.0100 - Time: 35.98s\n",
      "[EP 370/500] - Reward: 286.2873 - Steps: 362 - Eps: 0.0100 - Time: 55.90s\n",
      "[EP 371/500] - Reward: 257.6724 - Steps: 234 - Eps: 0.0100 - Time: 36.09s\n",
      "[EP 372/500] - Reward: 291.5797 - Steps: 259 - Eps: 0.0100 - Time: 40.28s\n",
      "[EP 373/500] - Reward: 291.8734 - Steps: 320 - Eps: 0.0100 - Time: 49.29s\n",
      "[EP 374/500] - Reward: 258.9894 - Steps: 204 - Eps: 0.0100 - Time: 32.14s\n",
      "[EP 375/500] - Reward: 248.2145 - Steps: 217 - Eps: 0.0100 - Time: 33.51s\n",
      "[EP 376/500] - Reward: 277.0741 - Steps: 274 - Eps: 0.0100 - Time: 42.18s\n",
      "[EP 377/500] - Reward: 29.6293 - Steps: 147 - Eps: 0.0100 - Time: 22.45s\n",
      "[EP 378/500] - Reward: 49.9041 - Steps: 162 - Eps: 0.0100 - Time: 25.39s\n",
      "[EP 379/500] - Reward: 74.1383 - Steps: 227 - Eps: 0.0100 - Time: 35.08s\n",
      "[EP 380/500] - Reward: 252.2568 - Steps: 386 - Eps: 0.0100 - Time: 59.73s\n",
      "[EP 381/500] - Reward: 254.1858 - Steps: 252 - Eps: 0.0100 - Time: 39.06s\n",
      "[EP 382/500] - Reward: 252.7135 - Steps: 316 - Eps: 0.0100 - Time: 48.89s\n",
      "[EP 383/500] - Reward: 259.2148 - Steps: 359 - Eps: 0.0100 - Time: 54.38s\n",
      "[EP 384/500] - Reward: 292.9730 - Steps: 251 - Eps: 0.0100 - Time: 39.66s\n",
      "[EP 385/500] - Reward: 273.5661 - Steps: 222 - Eps: 0.0100 - Time: 34.28s\n",
      "[EP 386/500] - Reward: 253.4206 - Steps: 216 - Eps: 0.0100 - Time: 33.25s\n",
      "[EP 387/500] - Reward: 225.5805 - Steps: 710 - Eps: 0.0100 - Time: 108.67s\n",
      "[EP 388/500] - Reward: 308.4591 - Steps: 215 - Eps: 0.0100 - Time: 33.30s\n",
      "[EP 389/500] - Reward: 281.5287 - Steps: 258 - Eps: 0.0100 - Time: 39.88s\n",
      "[EP 390/500] - Reward: -572.2836 - Steps: 467 - Eps: 0.0100 - Time: 71.65s\n",
      "[EP 391/500] - Reward: 116.0687 - Steps: 1000 - Eps: 0.0100 - Time: 154.81s\n",
      "[EP 392/500] - Reward: 264.6409 - Steps: 265 - Eps: 0.0100 - Time: 40.56s\n",
      "[EP 393/500] - Reward: 44.5083 - Steps: 174 - Eps: 0.0100 - Time: 27.19s\n",
      "[EP 394/500] - Reward: 271.5788 - Steps: 229 - Eps: 0.0100 - Time: 35.08s\n",
      "[EP 395/500] - Reward: 274.3726 - Steps: 259 - Eps: 0.0100 - Time: 40.12s\n",
      "[EP 396/500] - Reward: 274.9904 - Steps: 227 - Eps: 0.0100 - Time: 35.07s\n",
      "[EP 397/500] - Reward: 292.4133 - Steps: 227 - Eps: 0.0100 - Time: 35.94s\n",
      "[EP 398/500] - Reward: 286.2874 - Steps: 288 - Eps: 0.0100 - Time: 44.20s\n",
      "[EP 399/500] - Reward: 253.7578 - Steps: 221 - Eps: 0.0100 - Time: 33.96s\n",
      "[EP 400/500] - Reward: 284.8122 - Steps: 281 - Eps: 0.0100 - Time: 50.05s\n",
      "[EP 401/500] - Reward: -46.9080 - Steps: 142 - Eps: 0.0100 - Time: 21.34s\n",
      "[EP 402/500] - Reward: 261.6552 - Steps: 234 - Eps: 0.0100 - Time: 36.40s\n",
      "[EP 403/500] - Reward: 262.3487 - Steps: 206 - Eps: 0.0100 - Time: 32.25s\n",
      "[EP 404/500] - Reward: 241.4378 - Steps: 257 - Eps: 0.0100 - Time: 39.47s\n",
      "[EP 405/500] - Reward: 238.2864 - Steps: 257 - Eps: 0.0100 - Time: 39.05s\n",
      "[EP 406/500] - Reward: 250.9683 - Steps: 222 - Eps: 0.0100 - Time: 33.71s\n",
      "[EP 407/500] - Reward: 231.7780 - Steps: 448 - Eps: 0.0100 - Time: 68.84s\n",
      "[EP 408/500] - Reward: 268.8732 - Steps: 343 - Eps: 0.0100 - Time: 52.63s\n",
      "[EP 409/500] - Reward: 258.9662 - Steps: 245 - Eps: 0.0100 - Time: 37.95s\n",
      "[EP 410/500] - Reward: 290.5469 - Steps: 247 - Eps: 0.0100 - Time: 37.95s\n",
      "[EP 411/500] - Reward: -203.2428 - Steps: 227 - Eps: 0.0100 - Time: 35.39s\n",
      "[EP 412/500] - Reward: -0.6742 - Steps: 198 - Eps: 0.0100 - Time: 29.87s\n",
      "[EP 413/500] - Reward: 248.7391 - Steps: 505 - Eps: 0.0100 - Time: 77.23s\n",
      "[EP 414/500] - Reward: 291.0757 - Steps: 278 - Eps: 0.0100 - Time: 42.50s\n",
      "[EP 415/500] - Reward: 257.0755 - Steps: 269 - Eps: 0.0100 - Time: 41.63s\n",
      "[EP 416/500] - Reward: 277.2443 - Steps: 237 - Eps: 0.0100 - Time: 36.62s\n",
      "[EP 417/500] - Reward: 246.4965 - Steps: 262 - Eps: 0.0100 - Time: 40.51s\n",
      "[EP 418/500] - Reward: 32.2464 - Steps: 153 - Eps: 0.0100 - Time: 23.60s\n",
      "[EP 419/500] - Reward: 279.4679 - Steps: 245 - Eps: 0.0100 - Time: 37.61s\n",
      "[EP 420/500] - Reward: 279.5082 - Steps: 258 - Eps: 0.0100 - Time: 39.80s\n",
      "[EP 421/500] - Reward: 269.5379 - Steps: 210 - Eps: 0.0100 - Time: 32.61s\n",
      "[EP 422/500] - Reward: 233.9916 - Steps: 217 - Eps: 0.0100 - Time: 33.96s\n",
      "[EP 423/500] - Reward: 257.5173 - Steps: 325 - Eps: 0.0100 - Time: 50.01s\n",
      "[EP 424/500] - Reward: 244.9936 - Steps: 215 - Eps: 0.0100 - Time: 32.72s\n",
      "[EP 425/500] - Reward: 303.9452 - Steps: 290 - Eps: 0.0100 - Time: 45.75s\n",
      "[EP 426/500] - Reward: 36.2970 - Steps: 125 - Eps: 0.0100 - Time: 18.97s\n",
      "[EP 427/500] - Reward: 271.7702 - Steps: 225 - Eps: 0.0100 - Time: 34.88s\n",
      "[EP 428/500] - Reward: 239.2705 - Steps: 248 - Eps: 0.0100 - Time: 38.55s\n",
      "[EP 429/500] - Reward: 68.8012 - Steps: 175 - Eps: 0.0100 - Time: 26.53s\n",
      "[EP 430/500] - Reward: 224.1702 - Steps: 276 - Eps: 0.0100 - Time: 43.22s\n",
      "[EP 431/500] - Reward: 297.9434 - Steps: 272 - Eps: 0.0100 - Time: 41.81s\n",
      "[EP 432/500] - Reward: 286.5295 - Steps: 418 - Eps: 0.0100 - Time: 64.94s\n",
      "[EP 433/500] - Reward: 234.5134 - Steps: 274 - Eps: 0.0100 - Time: 42.70s\n",
      "[EP 434/500] - Reward: 249.5305 - Steps: 268 - Eps: 0.0100 - Time: 41.33s\n",
      "[EP 435/500] - Reward: 261.8214 - Steps: 207 - Eps: 0.0100 - Time: 31.80s\n",
      "[EP 436/500] - Reward: 249.3340 - Steps: 213 - Eps: 0.0100 - Time: 33.18s\n",
      "[EP 437/500] - Reward: 257.4434 - Steps: 248 - Eps: 0.0100 - Time: 38.45s\n",
      "[EP 438/500] - Reward: 266.1299 - Steps: 423 - Eps: 0.0100 - Time: 65.29s\n",
      "[EP 439/500] - Reward: 257.6686 - Steps: 413 - Eps: 0.0100 - Time: 64.70s\n",
      "[EP 440/500] - Reward: 267.4674 - Steps: 311 - Eps: 0.0100 - Time: 48.30s\n",
      "[EP 441/500] - Reward: 282.9177 - Steps: 244 - Eps: 0.0100 - Time: 38.25s\n",
      "[EP 442/500] - Reward: 248.7647 - Steps: 254 - Eps: 0.0100 - Time: 39.35s\n",
      "[EP 443/500] - Reward: 262.7223 - Steps: 287 - Eps: 0.0100 - Time: 45.00s\n",
      "[EP 444/500] - Reward: 276.2446 - Steps: 313 - Eps: 0.0100 - Time: 48.38s\n",
      "[EP 445/500] - Reward: -36.1053 - Steps: 141 - Eps: 0.0100 - Time: 21.81s\n",
      "[EP 446/500] - Reward: 258.7794 - Steps: 207 - Eps: 0.0100 - Time: 32.71s\n",
      "[EP 447/500] - Reward: 259.2283 - Steps: 552 - Eps: 0.0100 - Time: 86.98s\n",
      "[EP 448/500] - Reward: 231.9686 - Steps: 287 - Eps: 0.0100 - Time: 45.41s\n",
      "[EP 449/500] - Reward: 280.7038 - Steps: 328 - Eps: 0.0100 - Time: 51.99s\n",
      "[EP 450/500] - Reward: 292.1769 - Steps: 172 - Eps: 0.0100 - Time: 27.17s\n",
      "[EP 451/500] - Reward: 220.9422 - Steps: 625 - Eps: 0.0100 - Time: 98.15s\n",
      "[EP 452/500] - Reward: 270.7681 - Steps: 189 - Eps: 0.0100 - Time: 29.69s\n",
      "[EP 453/500] - Reward: 281.1289 - Steps: 236 - Eps: 0.0100 - Time: 36.12s\n",
      "[EP 454/500] - Reward: 242.1485 - Steps: 300 - Eps: 0.0100 - Time: 48.09s\n",
      "[EP 455/500] - Reward: 247.8785 - Steps: 246 - Eps: 0.0100 - Time: 38.21s\n",
      "[EP 456/500] - Reward: -288.2897 - Steps: 172 - Eps: 0.0100 - Time: 27.46s\n",
      "[EP 457/500] - Reward: 243.0669 - Steps: 268 - Eps: 0.0100 - Time: 42.27s\n",
      "[EP 458/500] - Reward: 282.5017 - Steps: 282 - Eps: 0.0100 - Time: 44.68s\n",
      "[EP 459/500] - Reward: 268.0578 - Steps: 217 - Eps: 0.0100 - Time: 33.91s\n",
      "[EP 460/500] - Reward: 288.2741 - Steps: 236 - Eps: 0.0100 - Time: 37.03s\n",
      "[EP 461/500] - Reward: 52.3545 - Steps: 150 - Eps: 0.0100 - Time: 23.95s\n",
      "[EP 462/500] - Reward: 281.7647 - Steps: 273 - Eps: 0.0100 - Time: 43.24s\n",
      "[EP 463/500] - Reward: 264.5630 - Steps: 187 - Eps: 0.0100 - Time: 29.93s\n",
      "[EP 464/500] - Reward: -159.9009 - Steps: 94 - Eps: 0.0100 - Time: 14.47s\n",
      "[EP 465/500] - Reward: 26.8722 - Steps: 153 - Eps: 0.0100 - Time: 24.39s\n",
      "[EP 466/500] - Reward: 7.0650 - Steps: 138 - Eps: 0.0100 - Time: 21.65s\n",
      "[EP 467/500] - Reward: 20.2480 - Steps: 1000 - Eps: 0.0100 - Time: 155.88s\n",
      "[EP 468/500] - Reward: 291.9997 - Steps: 302 - Eps: 0.0100 - Time: 47.13s\n",
      "[EP 469/500] - Reward: 46.8546 - Steps: 277 - Eps: 0.0100 - Time: 44.14s\n",
      "[EP 470/500] - Reward: 257.2252 - Steps: 336 - Eps: 0.0100 - Time: 52.34s\n",
      "[EP 471/500] - Reward: -122.3050 - Steps: 318 - Eps: 0.0100 - Time: 49.16s\n",
      "[EP 472/500] - Reward: -3.9560 - Steps: 291 - Eps: 0.0100 - Time: 45.15s\n",
      "[EP 473/500] - Reward: 278.3627 - Steps: 262 - Eps: 0.0100 - Time: 40.86s\n",
      "[EP 474/500] - Reward: 282.3678 - Steps: 222 - Eps: 0.0100 - Time: 34.12s\n",
      "[EP 475/500] - Reward: -15.7222 - Steps: 155 - Eps: 0.0100 - Time: 23.77s\n",
      "[EP 476/500] - Reward: -19.8646 - Steps: 91 - Eps: 0.0100 - Time: 13.57s\n",
      "[EP 477/500] - Reward: 291.1319 - Steps: 206 - Eps: 0.0100 - Time: 32.26s\n",
      "[EP 478/500] - Reward: 259.6340 - Steps: 408 - Eps: 0.0100 - Time: 63.17s\n",
      "[EP 479/500] - Reward: 197.1159 - Steps: 620 - Eps: 0.0100 - Time: 95.70s\n",
      "[EP 480/500] - Reward: 269.1299 - Steps: 339 - Eps: 0.0100 - Time: 52.35s\n",
      "[EP 481/500] - Reward: 217.1514 - Steps: 492 - Eps: 0.0100 - Time: 76.24s\n",
      "[EP 482/500] - Reward: 271.9209 - Steps: 281 - Eps: 0.0100 - Time: 43.88s\n",
      "[EP 483/500] - Reward: 253.3559 - Steps: 319 - Eps: 0.0100 - Time: 48.99s\n",
      "[EP 484/500] - Reward: 265.5764 - Steps: 400 - Eps: 0.0100 - Time: 61.83s\n",
      "[EP 485/500] - Reward: 283.9813 - Steps: 258 - Eps: 0.0100 - Time: 40.75s\n",
      "[EP 486/500] - Reward: 220.5018 - Steps: 306 - Eps: 0.0100 - Time: 47.12s\n",
      "[EP 487/500] - Reward: 263.2671 - Steps: 193 - Eps: 0.0100 - Time: 30.47s\n",
      "[EP 488/500] - Reward: -5.5131 - Steps: 180 - Eps: 0.0100 - Time: 28.32s\n",
      "[EP 489/500] - Reward: -1.2635 - Steps: 205 - Eps: 0.0100 - Time: 31.58s\n",
      "[EP 490/500] - Reward: 68.6834 - Steps: 181 - Eps: 0.0100 - Time: 28.38s\n",
      "[EP 491/500] - Reward: 282.8835 - Steps: 417 - Eps: 0.0100 - Time: 64.42s\n",
      "[EP 492/500] - Reward: -41.5424 - Steps: 582 - Eps: 0.0100 - Time: 90.78s\n",
      "[EP 493/500] - Reward: 264.8017 - Steps: 798 - Eps: 0.0100 - Time: 124.45s\n",
      "[EP 494/500] - Reward: 276.5730 - Steps: 327 - Eps: 0.0100 - Time: 50.34s\n",
      "[EP 495/500] - Reward: 238.9523 - Steps: 428 - Eps: 0.0100 - Time: 67.26s\n",
      "[EP 496/500] - Reward: 264.7956 - Steps: 285 - Eps: 0.0100 - Time: 43.82s\n",
      "[EP 497/500] - Reward: 8.1300 - Steps: 137 - Eps: 0.0100 - Time: 21.04s\n",
      "[EP 498/500] - Reward: 240.4652 - Steps: 728 - Eps: 0.0100 - Time: 113.79s\n",
      "[EP 499/500] - Reward: 259.5055 - Steps: 321 - Eps: 0.0100 - Time: 50.93s\n",
      "[EP 500/500] - Reward: 273.4521 - Steps: 477 - Eps: 0.0100 - Time: 86.24s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b32ca73177e4570a733bb1c833172eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epsilon</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>reward</td><td>▁▂▄▄▄▄▄▇▆▇▅▇▇▇▇▇▆▇██████▇█▆▇▇█████▇▇█▄██</td></tr><tr><td>steps</td><td>▁██████▅▆▃▁▁▃▂▁▂▆▁▁▁▂▁▁▂▂▃█▃▂▁▁▁▂▁▁▂▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epsilon</td><td>0.01</td></tr><tr><td>reward</td><td>273.45214</td></tr><tr><td>steps</td><td>477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">beaming-ox-46</strong>: <a href=\"https://wandb.ai/timothyckl/lunar-lander-rl/runs/3308mhhj\" target=\"_blank\">https://wandb.ai/timothyckl/lunar-lander-rl/runs/3308mhhj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230125_071110-3308mhhj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = DQL(env, learning_rate, discount_factor, exploration_rate)\n",
    "history = agent.train(episodes, max_steps, log_wandb=True, save_episodes=True, save_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0de76",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ccab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test agent\n",
    "history = agent.train(10, 1000, log_wandb=False, update_qnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1037bc27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T15:24:07.882079Z",
     "iopub.status.busy": "2023-01-25T15:24:07.881150Z",
     "iopub.status.idle": "2023-01-25T15:24:07.889495Z",
     "shell.execute_reply": "2023-01-25T15:24:07.888665Z"
    },
    "papermill": {
     "duration": 0.04083,
     "end_time": "2023-01-25T15:24:07.891435",
     "exception": false,
     "start_time": "2023-01-25T15:24:07.850605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save history\n",
    "if not os.path.exists('./history'):\n",
    "        os.mkdir('./history')\n",
    "\n",
    "with open('./history/dqn_history.json', 'w') as file:\n",
    "    json.dump(history, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 19 2022, 22:38:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29640.547849,
   "end_time": "2023-01-25T15:24:10.983975",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-25T07:10:10.436126",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "15c5baac91721a2e9125fc9e7830b5bd4b6688550f5daa42d124d7a05043362d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "142a3819660747a8808c0e7f9ded782e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b32ca73177e4570a733bb1c833172eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3d2558a5ccac4018b972fc31cc47e4f7",
        "IPY_MODEL_41b9bb8a5c3445dbb09c9e3df0e18b9c"
       ],
       "layout": "IPY_MODEL_aa0fced344484250b96dff9f3ebb95fb"
      }
     },
     "3d2558a5ccac4018b972fc31cc47e4f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b163f82537204c64a6858ca5f38db32a",
       "placeholder": "​",
       "style": "IPY_MODEL_b0cc6ed8557141438a8c281b4ab9638b",
       "value": "0.077 MB of 0.077 MB uploaded (0.000 MB deduped)\r"
      }
     },
     "41b9bb8a5c3445dbb09c9e3df0e18b9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_142a3819660747a8808c0e7f9ded782e",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7d9029c04bef423a8ab82e1c124340d1",
       "value": 1
      }
     },
     "7d9029c04bef423a8ab82e1c124340d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "aa0fced344484250b96dff9f3ebb95fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0cc6ed8557141438a8c281b4ab9638b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b163f82537204c64a6858ca5f38db32a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
